{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the robustness of model for the paper \"Confused or not Confused\" (https://github.com/nateanl/EEG_Classification)\n",
    "\n",
    "Just for loop the thing without seeding random generator and print average accuracy among other metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SubjectID', 'VideoID', 'Attention', 'Mediation', 'Raw', 'Delta', 'Theta', 'Alpha1', 'Alpha2', 'Beta1', 'Beta2', 'Gamma1', 'Gamma2', 'predefinedlabel', 'user-definedlabeln']\n",
      "14\n",
      "Begin LSTM model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/48/sarsas2/unix/miniconda3/envs/def/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(input_shape=(112, 12), axis=2)`\n",
      "/u/48/sarsas2/unix/miniconda3/envs/def/lib/python3.6/site-packages/ipykernel_launcher.py:94: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 112)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7de789fd2ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/def/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/def/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/def/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/def/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score \n",
    "\n",
    "\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "log= open('5_fold_log_1125.txt','w')\n",
    "features= []\n",
    "label = []\n",
    "feature = []\n",
    "with open('./EEG_data.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    i=0\n",
    "    for row in reader:\n",
    "        if(i==0):\n",
    "            i+=1\n",
    "            print(row)\n",
    "            continue\n",
    "        for i in range(0,len(row)):\n",
    "            row[i] = float(row[i])\n",
    "        features.append(row[0:14])\n",
    "        label.append(row[14])\n",
    "\n",
    "X = np.asarray(features)\n",
    "Y = np.asarray(label)\n",
    "features = {}\n",
    "output = {}\n",
    "print(X.shape[1])\n",
    "for i in range(X.shape[0]):\n",
    "    tu = int(X[i][0]*10 + X[i][1])\n",
    "    if tu not in list(features.keys()):\n",
    "        features[tu] = X[i][2:14]\n",
    "    elif features[tu].shape[0]<1344:\n",
    "        features[tu] = np.concatenate((features[tu],X[i][2:14]),axis =0)\n",
    "    output[tu]= Y[i]\n",
    "\n",
    "input = np.zeros((100,1344),dtype = float)\n",
    "labels = np.zeros((100,1),dtype = int)\n",
    "for i in list(features.keys()):\n",
    "    input[i,:] = features[i]\n",
    "    labels[i] = output[i]\n",
    "\n",
    "accs = []\n",
    "f1s = []\n",
    "roc_aucs = []\n",
    "for a in range(1):\n",
    "    print(\"Begin LSTM model\", a)\n",
    "    accuracy = 0.0\n",
    "    for i in range(0,5):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(input, labels, test_size=0.2)\n",
    "        X_train = X_train.reshape(80,112,12)\n",
    "        X_test = X_test.reshape(20,112,12)\n",
    "        y_train = np.zeros((80,112),dtype='int')\n",
    "        y_test = np.zeros((20,112),dtype='int')\n",
    "        y_train = np.repeat(Y_train,112, axis=1)\n",
    "        y_test = np.repeat(Y_test,112, axis=1)\n",
    "        # create the model\n",
    "        model = Sequential()\n",
    "        batch_size = 20\n",
    "        #model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length, dropout=0.2))\n",
    "        #model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization(input_shape=(112,12),mode =0,axis=2))\n",
    "        model.add(Bidirectional(LSTM(50, return_sequences=False, input_shape=(112,12)),merge_mode = 'ave'))\n",
    "        #model.add(Dropout(0.2))\n",
    "        #model.add(LSTM(200, return_sequences = False, input_length=1024))\n",
    "        model.add(Dense(112, activation='hard_sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['binary_accuracy'])\n",
    "        #print(model.summary())\n",
    "        model.fit(X_train, y_train,nb_epoch=2, verbose=0)\n",
    "        # Final evaluation of the model\n",
    "        scores = model.evaluate(X_test, y_test, batch_size = batch_size, verbose=0)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_test_flat = y_test.flatten()\n",
    "        y_pred_flat = y_pred.\n",
    "        print(y_pred.shape)\n",
    "        roc_auc = roc_auc_score(y_test.flatten(), y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print((\"Accuracy: %.2f%%\" % (scores[1]*100)))\n",
    "        log.write(str(scores[1])+'\\n')\n",
    "        accuracy += scores[1]\n",
    "        \n",
    "        accs.append(scores[1])\n",
    "        f1s.append(f1)\n",
    "        roc_aucs.append(roc_auc)\n",
    "    print('acc =', accuracy/5)\n",
    "    print('current avg acc =', np.mean(accs))\n",
    "\n",
    "for  metric, scores in {'accuracy':accs, 'F1':f1s, 'ROC-AUC':roc_aucs}.items():\n",
    "    print('Average {} for cross-validations: {:.3f}'.format(metric, np.mean(scores))) \n",
    "log.close() # you can omit in most cases as the destructor will call it\n",
    "\n",
    "#average accuracy: 0.690000013262"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
