{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDM_EEG_subtitlevecs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ktia-99qlzOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Running requires having the data on Google Drive or uploading the data to Colab via the left menu and setting the data path correctly.\n",
        "\n",
        "To use TPU, set \"tpu\" to True and hardware accelerator to \"TPU\" from Edit -> Notebook Settings"
      ]
    },
    {
      "metadata": {
        "id": "ePT0I-SulzyD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tpu = False\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "data_path = '/gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1MXnzbScS6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "if tpu:\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "def tpu_compatibilitate(model):\n",
        "  if tpu: return tf.contrib.tpu.keras_to_tpu_model(\n",
        "      model, strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "              tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "  else: return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIdDWtwHlstY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read data"
      ]
    },
    {
      "metadata": {
        "id": "s7bgJDMUOQKN",
        "colab_type": "code",
        "outputId": "269b4347-ba9e-48ed-d487-04628e739b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(data_path + 'EEG_data.csv')\n",
        "data.columns"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SubjectID', 'VideoID', 'Attention', 'Mediation', 'Raw', 'Delta',\n",
              "       'Theta', 'Alpha1', 'Alpha2', 'Beta1', 'Beta2', 'Gamma1', 'Gamma2',\n",
              "       'predefinedlabel', 'user-definedlabeln'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "s3igFo2wZz4H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The labels for confusion are the same for each video by subject"
      ]
    },
    {
      "metadata": {
        "id": "xR2ziDnpY2KP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for subjId in set(data.SubjectID):\n",
        "  for vidId in set(data.VideoID):\n",
        "    assert data.query('SubjectID == {} and VideoID == {}'\n",
        "                     .format(subjId, vidId))['user-definedlabeln'].mean() in (0.0, 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XS39to7ylnxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load subtitle vectors  \n"
      ]
    },
    {
      "metadata": {
        "id": "CZ4BFXIZVfYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "from csv\n",
        "\"\"\"\n",
        "#vid_dfs = pd.concat([pd.read_csv(notebook_path + 'subtitles/vid_{}_elmo_embedded_subs.csv'.format(i))\n",
        "#                     for i in range(10)], ignore_index=True\n",
        "#                   ).sort_values(['SubjectID', 'VideoID']).reset_index(drop=True)\n",
        "\n",
        "#vec_cols = [str(x) for x in range(1024)]\n",
        "\n",
        "#sub_vecs = vid_dfs[vec_cols].values.astype('float32')\n",
        "\n",
        "\"\"\"\n",
        "save/load from npy\n",
        "\"\"\"\n",
        "sub_vec_path = data_path + 'subtitle_vecs.npy'\n",
        "#np.save(sub_vec_path, sub_vecs)\n",
        "sub_vecs = np.load(sub_vec_path)\n",
        "sub_vec_dim = sub_vecs.shape[1]\n",
        "\n",
        "\"\"\"\n",
        "Make a dataset of original data combined with sub vecs \n",
        "\"\"\"\n",
        "dataset = np.hstack((data.values.astype('float32'), sub_vecs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BPnuOcx-lcHN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "PCA to reduce subtitle vector dimensions. Speeds up training and also has the potential to increase performance"
      ]
    },
    {
      "metadata": {
        "id": "B4CpmAOtgaKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\"\"\"\n",
        "PCA to reduce dimension of the word average vectors (might give better results)\n",
        "\"\"\"\n",
        "sub_vec_dim = 12\n",
        "pca = PCA(n_components=sub_vec_dim)\n",
        "pcad_sub_vecs = pca.fit_transform(sub_vecs)\n",
        "#dataset = np.hstack((data.values.astype('float32'), pcad_sub_vecs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKcDQdVTseQI",
        "colab_type": "code",
        "outputId": "bf8f59b8-65db-4dcc-e068-030a3c7f76ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12811, 1039)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "I7B9Ra-blV4T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing as is done in https://github.com/mehmani/DNNs-for-EEG-Signals/blob/master/DNNforEEFSignals.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "KUxzySen19sD",
        "colab_type": "code",
        "outputId": "0d360b98-d058-4137-ee62-e0ec2cf9638a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def NormSignal(S, I):\n",
        "    #normalize features\n",
        "    S=S.reshape(-1, 1)\n",
        "    if I not in [0, 1, 13, 14]:\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled = scaler.fit_transform(S)\n",
        "        scaled = scaled\n",
        "    else:\n",
        "        scaled = S\n",
        "    return scaled.reshape(-1).tolist()\n",
        "\n",
        "NormDataG = np.array([NormSignal(dataset[:,i], i) for i in range(dataset.shape[1])]).T\n",
        "print(NormDataG.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12811, 1039)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MR5eZ3s7lK90",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Additional metrics besides accuracy to have more information on model performance "
      ]
    },
    {
      "metadata": {
        "id": "BWzd23ZwzndW",
        "colab_type": "code",
        "outputId": "f35db6ad-016e-4d07-f266-13dc51f89f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def swap_tensor_binary_ints(x):\n",
        "    return tf.math.add(tf.negative(x), 1.)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(\"Test swapping tensor binary ints\")\n",
        "  diagonal = tf.linalg.diag(tf.ones((1, 2)))\n",
        "  print('orig:\\n', diagonal.eval())\n",
        "  print('swap:\\n', swap_tensor_binary_ints(diagonal).eval())\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_true =y_true\n",
        "    y_pred = tf.round(y_pred) # implicit 0.5 threshold via tf.round\n",
        "    y_correct = y_true * y_pred\n",
        "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
        "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
        "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
        "    precision = sum_correct / sum_pred\n",
        "    recall = sum_correct / sum_true\n",
        "    f_score = 2 * precision * recall / (precision + recall)\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return tf.reduce_mean(f_score)\n",
        "  \n",
        "def f1_flipped(y_true, y_pred):\n",
        "    y_true = y_true\n",
        "    y_pred = tf.round(y_pred) # implicit 0.5 threshold via tf.round\n",
        "    return f1_score(swap_tensor_binary_ints(y_true), \n",
        "                    swap_tensor_binary_ints(y_pred))\n",
        "\n",
        "def rocauc(y_true, y_pred):\n",
        "    roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test swapping tensor binary ints\n",
            "orig:\n",
            " [[[1. 0.]\n",
            "  [0. 1.]]]\n",
            "swap:\n",
            " [[[0. 1.]\n",
            "  [1. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fXrP2NC1LI57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cb65cd25-dc60-43a3-ab53-577f2a00b1ee"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import BatchNormalization\n",
        "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Flatten, Dropout, TimeDistributed, Conv2D, MaxPooling2D, Masking\n",
        "\n",
        "\"\"\"\n",
        "Model from the paper \"confused or not confused\"\n",
        "\"\"\"\n",
        "def get_model_timedist(intervals, n_dim=11):\n",
        "    model = Sequential([\n",
        "        #Masking(mask_value=0, input_shape=(A, n_dim)), # Masking does not help for some reason (should help with padded data?)\n",
        "        BatchNormalization(input_shape=(intervals, n_dim), axis=2), # New version of keras doesn't support \"mode\" attribute, which was used in the original code (mode=0)\n",
        "        Bidirectional(LSTM(50, return_sequences=False, activation='selu'), input_shape=(intervals, n_dim)),\n",
        "        Dense(intervals, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
        "                  metrics=['binary_accuracy', f1_score, f1_flipped])\n",
        "    return model, (-1, intervals, n_dim)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f86511a0b38>,\n",
              " (-1, 10, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "7qF7LfkrvpA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model from the paper \"confused or not confused\" with binary output per data point\n",
        "\n",
        "\"\"\"\n",
        "def get_model(intervals, n_dim=11):\n",
        "    model = Sequential([\n",
        "        #Masking(mask_value=0, input_shape=(A, n_dim)), # Masking does not help for some reason (should help with padded data?)\n",
        "        BatchNormalization(input_shape=(intervals, n_dim), axis=2),\n",
        "        Bidirectional(LSTM(50, return_sequences=False, activation='selu'), input_shape=(intervals, n_dim)),\n",
        "        #Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adagrad',\n",
        "                  metrics=['acc', f1_score, f1_flipped])\n",
        "    return model, (-1, intervals, n_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C56mNBEsON09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_mehmani_model(intervals, n_dim=11):\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv2D(20, (5,5), activation='relu'),\n",
        "              input_shape=(1, intervals, n_dims, 1)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(10, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
        "    model.add(LSTM(10))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', f1_score, f1_flipped])\n",
        "    return model, (-1, 1, intervals, n_dim, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rGzLNvsWiJEQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Functions for making the data amount of intervals the same for each data point"
      ]
    },
    {
      "metadata": {
        "id": "9C1tx41gY163",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def min_max_rows_per_subject_vid(X):\n",
        "  VideoID = list(set(X[:,1]))\n",
        "  SubjectID = list(set(X[:,0]))\n",
        "\n",
        "  max_intervals = 0 # length of signal\n",
        "  min_intervals = len(X)\n",
        "  \n",
        "  for subId in SubjectID:\n",
        "      for vidId in VideoID:\n",
        "          X_tmp=X[(X[:, 0] == subId) & (X[:, 1] == vidId)]\n",
        "          max_intervals = max(len(X_tmp), max_intervals)\n",
        "          min_intervals = min(len(X_tmp), min_intervals)\n",
        "  print(max_intervals)\n",
        "  print(min_intervals)\n",
        "  assert max_intervals == 144\n",
        "  return min_intervals, max_intervals\n",
        "\n",
        "min_intervals, max_intervals = min_max_rows_per_subject_vid(dataset)\n",
        "\n",
        "\n",
        "def zero_pad_data(X, max_intervals, y_col):\n",
        "  # Manual Padding to fixed size:\n",
        "    X_pad = None\n",
        "    VideoID = list(set(X[:,1]))\n",
        "    SubjectID = list(set(X[:,0])) \n",
        "    for subId in SubjectID:\n",
        "        for vidId in VideoID:\n",
        "            X_sv = X[(X[:,0]==subId) & (X[:,1]==vidId)]\n",
        "            pad_len = max_intervals - X_sv.shape[0]\n",
        "            \n",
        "            z = np.zeros((pad_len, X_sv.shape[1]), dtype=X_sv.dtype)\n",
        "            z[:,0] = X_sv[:,0][pad_len]\n",
        "            z[:,1] = X_sv[:,1][pad_len]\n",
        "            z[:,y_col] = X_sv[:,y_col][pad_len]\n",
        "            \n",
        "            X_sv_pad = np.concatenate((X_sv, z), axis=0)\n",
        "            X_sv_pad = X_sv_pad.reshape(1, max_intervals, -1)\n",
        "\n",
        "            X_pad = X_sv_pad if X_pad is None else np.vstack((X_pad,X_sv_pad))\n",
        "            \n",
        "    return X_pad\n",
        "\n",
        "def truncate_data(X, min_intervals, y_col):\n",
        "    X_trunc = None\n",
        "    VideoID = list(set(X[:,1]))\n",
        "    SubjectID = list(set(X[:,0]))\n",
        "    for vidId in VideoID:\n",
        "      for subId in SubjectID:\n",
        "          X_sv = X[(X[:,0]==subId) & (X[:,1]==vidId)]\n",
        "          trunc_len = min_intervals\n",
        "          X_sv_trunc = X_sv[0:trunc_len].reshape(1, min_intervals, -1)\n",
        "          X_trunc = X_sv_trunc if X_trunc is None else np.vstack((X_trunc, X_sv_trunc))\n",
        "    return X_trunc\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0L2NggfwhVsj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define target variable and which variables to use for training"
      ]
    },
    {
      "metadata": {
        "id": "1roletOchUkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y_col = 14 # The student's confusion column\n",
        "orig_train_data_cols = list(range(2,14))\n",
        "vector_cols = list(np.arange(sub_vec_dim) + 15) \n",
        "\n",
        "train_cols = orig_train_data_cols + vector_cols\n",
        "n_dim = len(train_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDoCgF4Yhx7T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cross-validation"
      ]
    },
    {
      "metadata": {
        "id": "5dGDbJpDS_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from time import time\n",
        "\n",
        "def train_eval_model(model, X_train, y_train, X_test, y_test, train_cols, intervals,\n",
        "                     epochs=20, batch_size=20, verbose=1): \n",
        "    start = time()\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test), verbose=verbose, shuffle=True)\n",
        "    print('model trained in {:.3f} seconds'.format(time() - start))\n",
        "\n",
        "    loss, acc, f1, f1_flip = model.evaluate(X_test, y_test, verbose=0)\n",
        "    #y_pred = model.predict(X_test).ravel()\n",
        "    #roc_auc = rocauc(y_test, y_pred)\n",
        "    return (acc, f1, f1_flip, history)\n",
        "\n",
        " \n",
        "def cross_validate(model, X_shape, data, intervals, even_data, n_test=2,\n",
        "                   time_distributed=False, verbose=1, epochs=50, batch_size=20):\n",
        "  \"\"\"\n",
        "  even_data: either truncate_data or zero_pad_data to make number of intervals\n",
        "             even for each data point\n",
        "  \"\"\"\n",
        "  results = []\n",
        "  initial_weights = model.get_weights()\n",
        "\n",
        "  for i in range(0, 10, n_test):\n",
        "    model.set_weights(initial_weights) # Reset weights to forget training done on current iteration's test data  \n",
        "    \n",
        "    data_train = even_data(data[np.in1d(data[:,0], (i, i+1), invert=True)], intervals, y_col=y_col)\n",
        "    data_test = even_data(data[np.in1d(data[:,0], (i, i+1))], intervals, y_col=y_col)\n",
        "    X_train = data_train[:, :, train_cols]\n",
        "    y_train = data_train[:, :, y_col]\n",
        "    X_test = data_test[:, :, train_cols]\n",
        "    y_test = data_test[:, :, y_col]\n",
        "\n",
        "    X_train = X_train.reshape(X_shape)\n",
        "    print('Xtrain shape', X_train.shape)\n",
        "    X_test = X_test.reshape(X_shape)\n",
        "    print('Xtest shape', X_test.shape)\n",
        "    \n",
        "    if not time_distributed: y_train = y_train.reshape(-1, intervals).mean(axis=1)\n",
        "    print('ytrain shape', y_train.shape)\n",
        "    if not time_distributed: y_test = y_test.reshape(-1, intervals).mean(axis=1)\n",
        "    print('ytest shape', y_test.shape)\n",
        "\n",
        "    start = time()\n",
        "    print('{}-fold cross validation, iteration {}'\n",
        "          .format(int(10/n_test), len(results) +1))\n",
        "    acc, f1, f1_flip, history = train_eval_model(model, X_train, y_train,\n",
        "                                                 X_test, y_test,\n",
        "                                                 train_cols, intervals,\n",
        "                                                 epochs=epochs, batch_size=batch_size,\n",
        "                                                 verbose=verbose)\n",
        "    \n",
        "    results.append({'acc': acc, 'F1': f1, 'F1-flipped': f1_flip})\n",
        "    \n",
        "    print('current cross-validation mean accuracy: {:.3f}, f1: {:.3f}, and f1 flipped: {:.3f}'.format(\n",
        "          *[np.mean([r[key] for r in results]) for key in results[0].keys()]))\n",
        "    print('cross-validation total time: {:.3f} seconds'.format(time() - start))\n",
        "\n",
        "  return results\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sjlQWCQUjPb",
        "colab_type": "code",
        "outputId": "c9605b7f-1606-4fbc-8b30-7013b62c3816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test Mehmani's model \n",
        "\"\"\"\n",
        "#model, input_shape = get_mehmani_model(max_intervals, n_dims)\n",
        "#results = cross_validate(model=model, X_shape=input_shape, data=NormDataG,\n",
        "#                         intervals=max_intervals, even_data=zero_pad_data, n_test=2)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTest Mehmani's model \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "vD1kWnUNJonX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(*results, sep='\\n')\n",
        "#print('cross-validation mean accuracy: {:.3f}, f1: {:.3f}, and f1 flipped: {:.3f}'.format(\n",
        "#       *[np.mean([r[key] for r in results]) for key in results[0].keys()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C1wWBL4WTNG3",
        "colab_type": "code",
        "outputId": "731d214b-1dba-4ae3-da3d-077acb2f8a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5308
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test the model from the paper \"Confused or not confused\"\n",
        "\"\"\"\n",
        "train_cols = orig_train_data_cols\n",
        "n_dim = len(train_cols)\n",
        "model, input_shape = get_model_timedist(min_intervals, n_dim)\n",
        "tpu_model = tpu_compatibilitate(model)\n",
        "\n",
        "results = cross_validate(model=tpu_model, X_shape=input_shape, data=dataset,\n",
        "                         time_distributed=True,\n",
        "                         intervals=min_intervals, even_data=truncate_data,\n",
        "                         n_test=2, verbose=1, epochs=25, batch_size=20)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain shape (80, 112, 12)\n",
            "Xtest shape (20, 112, 12)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 1\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 8s 98ms/step - loss: 0.7024 - binary_accuracy: 0.4972 - f1_score: 0.3451 - f1_flipped: 0.3163 - val_loss: 7.8012 - val_binary_accuracy: 0.5071 - val_f1_score: 0.2872 - val_f1_flipped: 0.3846\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6909 - binary_accuracy: 0.5305 - f1_score: 0.3708 - f1_flipped: 0.3067 - val_loss: 7.4780 - val_binary_accuracy: 0.5170 - val_f1_score: 0.2831 - val_f1_flipped: 0.3966\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6791 - binary_accuracy: 0.5589 - f1_score: 0.3836 - f1_flipped: 0.3109 - val_loss: 7.6933 - val_binary_accuracy: 0.5174 - val_f1_score: 0.2984 - val_f1_flipped: 0.3820\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6659 - binary_accuracy: 0.5854 - f1_score: 0.3933 - f1_flipped: 0.3034 - val_loss: 7.8887 - val_binary_accuracy: 0.5067 - val_f1_score: 0.3166 - val_f1_flipped: 0.3550\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 1.0619 - binary_accuracy: 0.6064 - f1_score: 0.3835 - f1_flipped: 0.3163 - val_loss: 7.9802 - val_binary_accuracy: 0.4862 - val_f1_score: 0.2971 - val_f1_flipped: 0.3555\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6601 - binary_accuracy: 0.6170 - f1_score: 0.3697 - f1_flipped: 0.3273 - val_loss: 7.1984 - val_binary_accuracy: 0.5281 - val_f1_score: 0.3118 - val_f1_flipped: 0.3737\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6266 - binary_accuracy: 0.6368 - f1_score: 0.3899 - f1_flipped: 0.3289 - val_loss: 5.7082 - val_binary_accuracy: 0.5196 - val_f1_score: 0.3189 - val_f1_flipped: 0.3537\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6154 - binary_accuracy: 0.6468 - f1_score: 0.3785 - f1_flipped: 0.3301 - val_loss: 4.2471 - val_binary_accuracy: 0.5232 - val_f1_score: 0.3355 - val_f1_flipped: 0.3282\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6100 - binary_accuracy: 0.6487 - f1_score: 0.3810 - f1_flipped: 0.3235 - val_loss: 3.3935 - val_binary_accuracy: 0.5295 - val_f1_score: 0.3323 - val_f1_flipped: 0.3394\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.6147 - binary_accuracy: 0.6626 - f1_score: 0.3779 - f1_flipped: 0.3357 - val_loss: 2.3927 - val_binary_accuracy: 0.5455 - val_f1_score: 0.3584 - val_f1_flipped: 0.3124\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5998 - binary_accuracy: 0.6433 - f1_score: 0.3536 - f1_flipped: 0.3323 - val_loss: 1.6277 - val_binary_accuracy: 0.5580 - val_f1_score: 0.3802 - val_f1_flipped: 0.3003\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 0.5965 - binary_accuracy: 0.6830 - f1_score: 0.3893 - f1_flipped: 0.3312 - val_loss: 0.9329 - val_binary_accuracy: 0.5946 - val_f1_score: 0.3971 - val_f1_flipped: 0.3103\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5807 - binary_accuracy: 0.6753 - f1_score: 0.3883 - f1_flipped: 0.3177 - val_loss: 1.0474 - val_binary_accuracy: 0.5603 - val_f1_score: 0.3670 - val_f1_flipped: 0.3157\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6429 - binary_accuracy: 0.6371 - f1_score: 0.3574 - f1_flipped: 0.3205 - val_loss: 0.6815 - val_binary_accuracy: 0.5603 - val_f1_score: 0.3830 - val_f1_flipped: 0.2761\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5888 - binary_accuracy: 0.6743 - f1_score: 0.3839 - f1_flipped: 0.3409 - val_loss: 0.6522 - val_binary_accuracy: 0.5567 - val_f1_score: 0.3820 - val_f1_flipped: 0.2667\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.5826 - binary_accuracy: 0.6503 - f1_score: 0.3591 - f1_flipped: 0.3346 - val_loss: 0.6519 - val_binary_accuracy: 0.5460 - val_f1_score: 0.3748 - val_f1_flipped: 0.2575\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5494 - binary_accuracy: 0.6799 - f1_score: 0.3839 - f1_flipped: 0.3333 - val_loss: 0.6345 - val_binary_accuracy: 0.5527 - val_f1_score: 0.3661 - val_f1_flipped: 0.2723\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5335 - binary_accuracy: 0.7283 - f1_score: 0.3849 - f1_flipped: 0.3870 - val_loss: 0.6195 - val_binary_accuracy: 0.5661 - val_f1_score: 0.3575 - val_f1_flipped: 0.2835\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.5408 - binary_accuracy: 0.6953 - f1_score: 0.3706 - f1_flipped: 0.3586 - val_loss: 0.7004 - val_binary_accuracy: 0.5754 - val_f1_score: 0.3488 - val_f1_flipped: 0.3227\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6635 - binary_accuracy: 0.6888 - f1_score: 0.3604 - f1_flipped: 0.3630 - val_loss: 1.1864 - val_binary_accuracy: 0.5509 - val_f1_score: 0.3486 - val_f1_flipped: 0.2855\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.5433 - binary_accuracy: 0.6907 - f1_score: 0.3603 - f1_flipped: 0.3685 - val_loss: 1.0412 - val_binary_accuracy: 0.5723 - val_f1_score: 0.3516 - val_f1_flipped: 0.3001\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.5313 - binary_accuracy: 0.7140 - f1_score: 0.3558 - f1_flipped: 0.3894 - val_loss: 1.1784 - val_binary_accuracy: 0.5603 - val_f1_score: 0.3402 - val_f1_flipped: 0.3008\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6176 - binary_accuracy: 0.6542 - f1_score: 0.3666 - f1_flipped: 0.3268 - val_loss: 0.6190 - val_binary_accuracy: 0.5170 - val_f1_score: 0.3510 - val_f1_flipped: 0.2265\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.8899 - binary_accuracy: 0.6972 - f1_score: 0.3479 - f1_flipped: 0.3872 - val_loss: 0.6379 - val_binary_accuracy: 0.5165 - val_f1_score: 0.3451 - val_f1_flipped: 0.2283\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6111 - binary_accuracy: 0.7623 - f1_score: 0.4024 - f1_flipped: 0.3918 - val_loss: 0.6741 - val_binary_accuracy: 0.5201 - val_f1_score: 0.3450 - val_f1_flipped: 0.2288\n",
            "model trained in 119.493 seconds\n",
            "current cross-validation mean accuracy: 0.520, f1: 0.345, and f1 flipped: 0.229\n",
            "cross-validation total time: 119.865 seconds\n",
            "Xtrain shape (80, 112, 12)\n",
            "Xtest shape (20, 112, 12)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 2\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7040 - binary_accuracy: 0.5007 - f1_score: 0.3384 - f1_flipped: 0.3276 - val_loss: 7.7831 - val_binary_accuracy: 0.4884 - val_f1_score: 0.3219 - val_f1_flipped: 0.3337\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7005 - binary_accuracy: 0.5083 - f1_score: 0.3441 - f1_flipped: 0.3279 - val_loss: 7.7585 - val_binary_accuracy: 0.4911 - val_f1_score: 0.3193 - val_f1_flipped: 0.3386\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.6957 - binary_accuracy: 0.5164 - f1_score: 0.3510 - f1_flipped: 0.3275 - val_loss: 7.4161 - val_binary_accuracy: 0.5045 - val_f1_score: 0.3235 - val_f1_flipped: 0.3455\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6956 - binary_accuracy: 0.5209 - f1_score: 0.3479 - f1_flipped: 0.3321 - val_loss: 7.7123 - val_binary_accuracy: 0.4862 - val_f1_score: 0.3255 - val_f1_flipped: 0.3271\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6888 - binary_accuracy: 0.5440 - f1_score: 0.3648 - f1_flipped: 0.3343 - val_loss: 7.7704 - val_binary_accuracy: 0.4812 - val_f1_score: 0.3273 - val_f1_flipped: 0.3201\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6838 - binary_accuracy: 0.5558 - f1_score: 0.3671 - f1_flipped: 0.3389 - val_loss: 7.9558 - val_binary_accuracy: 0.4652 - val_f1_score: 0.3207 - val_f1_flipped: 0.3110\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6862 - binary_accuracy: 0.5483 - f1_score: 0.3671 - f1_flipped: 0.3258 - val_loss: 7.5124 - val_binary_accuracy: 0.4857 - val_f1_score: 0.3337 - val_f1_flipped: 0.3154\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6764 - binary_accuracy: 0.5778 - f1_score: 0.3763 - f1_flipped: 0.3418 - val_loss: 7.5424 - val_binary_accuracy: 0.4817 - val_f1_score: 0.3258 - val_f1_flipped: 0.3178\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6755 - binary_accuracy: 0.5789 - f1_score: 0.3743 - f1_flipped: 0.3365 - val_loss: 7.2876 - val_binary_accuracy: 0.4795 - val_f1_score: 0.3403 - val_f1_flipped: 0.3004\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 0.6730 - binary_accuracy: 0.5859 - f1_score: 0.3747 - f1_flipped: 0.3375 - val_loss: 6.7426 - val_binary_accuracy: 0.4951 - val_f1_score: 0.3398 - val_f1_flipped: 0.3126\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 0.6676 - binary_accuracy: 0.6013 - f1_score: 0.3883 - f1_flipped: 0.3291 - val_loss: 5.4882 - val_binary_accuracy: 0.5210 - val_f1_score: 0.3150 - val_f1_flipped: 0.3491\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6553 - binary_accuracy: 0.6366 - f1_score: 0.3914 - f1_flipped: 0.3540 - val_loss: 5.2758 - val_binary_accuracy: 0.4795 - val_f1_score: 0.2522 - val_f1_flipped: 0.3514\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6528 - binary_accuracy: 0.6254 - f1_score: 0.3893 - f1_flipped: 0.3360 - val_loss: 4.6763 - val_binary_accuracy: 0.4879 - val_f1_score: 0.2406 - val_f1_flipped: 0.3615\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6541 - binary_accuracy: 0.6152 - f1_score: 0.3951 - f1_flipped: 0.3162 - val_loss: 4.4736 - val_binary_accuracy: 0.4746 - val_f1_score: 0.2125 - val_f1_flipped: 0.3662\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6409 - binary_accuracy: 0.6398 - f1_score: 0.3921 - f1_flipped: 0.3308 - val_loss: 4.1912 - val_binary_accuracy: 0.5067 - val_f1_score: 0.2168 - val_f1_flipped: 0.3747\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.9440 - binary_accuracy: 0.6627 - f1_score: 0.3789 - f1_flipped: 0.3605 - val_loss: 3.3851 - val_binary_accuracy: 0.5263 - val_f1_score: 0.2232 - val_f1_flipped: 0.3814\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7155 - binary_accuracy: 0.6378 - f1_score: 0.3853 - f1_flipped: 0.3305 - val_loss: 2.4072 - val_binary_accuracy: 0.4799 - val_f1_score: 0.1923 - val_f1_flipped: 0.3514\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6108 - binary_accuracy: 0.6748 - f1_score: 0.3797 - f1_flipped: 0.3567 - val_loss: 2.1499 - val_binary_accuracy: 0.4902 - val_f1_score: 0.1985 - val_f1_flipped: 0.3490\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6762 - binary_accuracy: 0.6704 - f1_score: 0.3893 - f1_flipped: 0.3427 - val_loss: 2.5216 - val_binary_accuracy: 0.4728 - val_f1_score: 0.1946 - val_f1_flipped: 0.3421\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6381 - binary_accuracy: 0.7026 - f1_score: 0.3802 - f1_flipped: 0.3741 - val_loss: 3.3898 - val_binary_accuracy: 0.4808 - val_f1_score: 0.2652 - val_f1_flipped: 0.3442\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.4091 - binary_accuracy: 0.6665 - f1_score: 0.3597 - f1_flipped: 0.3707 - val_loss: 4.2262 - val_binary_accuracy: 0.5241 - val_f1_score: 0.2008 - val_f1_flipped: 0.4167\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.0720 - binary_accuracy: 0.6390 - f1_score: 0.3510 - f1_flipped: 0.3575 - val_loss: 3.9359 - val_binary_accuracy: 0.4763 - val_f1_score: 0.1714 - val_f1_flipped: 0.3797\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 1.2216 - binary_accuracy: 0.6555 - f1_score: 0.3744 - f1_flipped: 0.3437 - val_loss: 3.2433 - val_binary_accuracy: 0.4906 - val_f1_score: 0.1784 - val_f1_flipped: 0.3873\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 1.4791 - binary_accuracy: 0.6679 - f1_score: 0.3620 - f1_flipped: 0.3680 - val_loss: 3.5100 - val_binary_accuracy: 0.4732 - val_f1_score: 0.1585 - val_f1_flipped: 0.3882\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 1.3119 - binary_accuracy: 0.6702 - f1_score: 0.3632 - f1_flipped: 0.3660 - val_loss: 3.3428 - val_binary_accuracy: 0.4866 - val_f1_score: 0.1757 - val_f1_flipped: 0.3812\n",
            "model trained in 111.386 seconds\n",
            "current cross-validation mean accuracy: 0.503, f1: 0.260, and f1 flipped: 0.305\n",
            "cross-validation total time: 111.746 seconds\n",
            "Xtrain shape (80, 112, 12)\n",
            "Xtest shape (20, 112, 12)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 3\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7045 - binary_accuracy: 0.4978 - f1_score: 0.3240 - f1_flipped: 0.3392 - val_loss: 7.8835 - val_binary_accuracy: 0.5085 - val_f1_score: 0.3901 - val_f1_flipped: 0.2831\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7010 - binary_accuracy: 0.5069 - f1_score: 0.3226 - f1_flipped: 0.3480 - val_loss: 8.0468 - val_binary_accuracy: 0.4969 - val_f1_score: 0.3883 - val_f1_flipped: 0.2750\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6982 - binary_accuracy: 0.5146 - f1_score: 0.3230 - f1_flipped: 0.3537 - val_loss: 8.0768 - val_binary_accuracy: 0.4938 - val_f1_score: 0.3816 - val_f1_flipped: 0.2786\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6946 - binary_accuracy: 0.5217 - f1_score: 0.3276 - f1_flipped: 0.3533 - val_loss: 7.9454 - val_binary_accuracy: 0.5040 - val_f1_score: 0.3903 - val_f1_flipped: 0.2790\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6956 - binary_accuracy: 0.5234 - f1_score: 0.3263 - f1_flipped: 0.3526 - val_loss: 8.0279 - val_binary_accuracy: 0.4978 - val_f1_score: 0.3863 - val_f1_flipped: 0.2773\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6926 - binary_accuracy: 0.5247 - f1_score: 0.3267 - f1_flipped: 0.3502 - val_loss: 8.0502 - val_binary_accuracy: 0.4938 - val_f1_score: 0.3851 - val_f1_flipped: 0.2748\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6880 - binary_accuracy: 0.5442 - f1_score: 0.3262 - f1_flipped: 0.3672 - val_loss: 7.8657 - val_binary_accuracy: 0.4996 - val_f1_score: 0.3921 - val_f1_flipped: 0.2736\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6844 - binary_accuracy: 0.5483 - f1_score: 0.3237 - f1_flipped: 0.3683 - val_loss: 7.7859 - val_binary_accuracy: 0.5121 - val_f1_score: 0.3980 - val_f1_flipped: 0.2781\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6824 - binary_accuracy: 0.5552 - f1_score: 0.3214 - f1_flipped: 0.3685 - val_loss: 8.0608 - val_binary_accuracy: 0.4871 - val_f1_score: 0.3899 - val_f1_flipped: 0.2638\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6789 - binary_accuracy: 0.5698 - f1_score: 0.3241 - f1_flipped: 0.3734 - val_loss: 7.6558 - val_binary_accuracy: 0.4946 - val_f1_score: 0.3947 - val_f1_flipped: 0.2652\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6782 - binary_accuracy: 0.5737 - f1_score: 0.3229 - f1_flipped: 0.3745 - val_loss: 6.8819 - val_binary_accuracy: 0.4973 - val_f1_score: 0.3990 - val_f1_flipped: 0.2629\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6742 - binary_accuracy: 0.5814 - f1_score: 0.3214 - f1_flipped: 0.3741 - val_loss: 5.9081 - val_binary_accuracy: 0.4973 - val_f1_score: 0.4118 - val_f1_flipped: 0.2466\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6743 - binary_accuracy: 0.5801 - f1_score: 0.3107 - f1_flipped: 0.3735 - val_loss: 5.7551 - val_binary_accuracy: 0.5179 - val_f1_score: 0.4331 - val_f1_flipped: 0.2394\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6715 - binary_accuracy: 0.5922 - f1_score: 0.3181 - f1_flipped: 0.3728 - val_loss: 5.4427 - val_binary_accuracy: 0.5304 - val_f1_score: 0.4426 - val_f1_flipped: 0.2399\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6624 - binary_accuracy: 0.6078 - f1_score: 0.3109 - f1_flipped: 0.3879 - val_loss: 4.4471 - val_binary_accuracy: 0.5464 - val_f1_score: 0.4583 - val_f1_flipped: 0.2328\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6682 - binary_accuracy: 0.5855 - f1_score: 0.3076 - f1_flipped: 0.3686 - val_loss: 3.3184 - val_binary_accuracy: 0.5379 - val_f1_score: 0.4705 - val_f1_flipped: 0.2051\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6518 - binary_accuracy: 0.6180 - f1_score: 0.3161 - f1_flipped: 0.3853 - val_loss: 2.7231 - val_binary_accuracy: 0.5362 - val_f1_score: 0.4848 - val_f1_flipped: 0.1729\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6431 - binary_accuracy: 0.6450 - f1_score: 0.3238 - f1_flipped: 0.3909 - val_loss: 2.0633 - val_binary_accuracy: 0.5103 - val_f1_score: 0.4937 - val_f1_flipped: 0.1245\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6386 - binary_accuracy: 0.6374 - f1_score: 0.3171 - f1_flipped: 0.3882 - val_loss: 1.8112 - val_binary_accuracy: 0.5085 - val_f1_score: 0.5120 - val_f1_flipped: 0.0844\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6397 - binary_accuracy: 0.6431 - f1_score: 0.3244 - f1_flipped: 0.3832 - val_loss: 1.9304 - val_binary_accuracy: 0.5089 - val_f1_score: 0.5197 - val_f1_flipped: 0.0657\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6372 - binary_accuracy: 0.6337 - f1_score: 0.3159 - f1_flipped: 0.3753 - val_loss: 1.3939 - val_binary_accuracy: 0.5393 - val_f1_score: 0.5399 - val_f1_flipped: 0.0648\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6253 - binary_accuracy: 0.6345 - f1_score: 0.3055 - f1_flipped: 0.3773 - val_loss: 1.1907 - val_binary_accuracy: 0.5719 - val_f1_score: 0.5582 - val_f1_flipped: 0.0689\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6111 - binary_accuracy: 0.6676 - f1_score: 0.3161 - f1_flipped: 0.3997 - val_loss: 1.2162 - val_binary_accuracy: 0.5844 - val_f1_score: 0.5724 - val_f1_flipped: 0.0508\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6534 - binary_accuracy: 0.6616 - f1_score: 0.2955 - f1_flipped: 0.4200 - val_loss: 1.0523 - val_binary_accuracy: 0.5790 - val_f1_score: 0.5790 - val_f1_flipped: 0.0237\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6101 - binary_accuracy: 0.6689 - f1_score: 0.2932 - f1_flipped: 0.4283 - val_loss: 1.1006 - val_binary_accuracy: 0.5750 - val_f1_score: 0.5774 - val_f1_flipped: 0.0186\n",
            "model trained in 109.607 seconds\n",
            "current cross-validation mean accuracy: 0.527, f1: 0.366, and f1 flipped: 0.210\n",
            "cross-validation total time: 109.959 seconds\n",
            "Xtrain shape (80, 112, 12)\n",
            "Xtest shape (20, 112, 12)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 4\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7023 - binary_accuracy: 0.5018 - f1_score: 0.3350 - f1_flipped: 0.3318 - val_loss: 7.4240 - val_binary_accuracy: 0.4844 - val_f1_score: 0.3640 - val_f1_flipped: 0.2874\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6953 - binary_accuracy: 0.5205 - f1_score: 0.3421 - f1_flipped: 0.3391 - val_loss: 7.2295 - val_binary_accuracy: 0.4799 - val_f1_score: 0.3534 - val_f1_flipped: 0.2938\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6879 - binary_accuracy: 0.5392 - f1_score: 0.3513 - f1_flipped: 0.3425 - val_loss: 7.1194 - val_binary_accuracy: 0.4830 - val_f1_score: 0.3486 - val_f1_flipped: 0.2995\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6846 - binary_accuracy: 0.5493 - f1_score: 0.3523 - f1_flipped: 0.3415 - val_loss: 6.7513 - val_binary_accuracy: 0.4924 - val_f1_score: 0.3674 - val_f1_flipped: 0.2903\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6811 - binary_accuracy: 0.5587 - f1_score: 0.3535 - f1_flipped: 0.3439 - val_loss: 7.2854 - val_binary_accuracy: 0.4732 - val_f1_score: 0.3467 - val_f1_flipped: 0.2920\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6761 - binary_accuracy: 0.5741 - f1_score: 0.3545 - f1_flipped: 0.3496 - val_loss: 6.8439 - val_binary_accuracy: 0.4795 - val_f1_score: 0.3498 - val_f1_flipped: 0.2948\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6737 - binary_accuracy: 0.5804 - f1_score: 0.3555 - f1_flipped: 0.3457 - val_loss: 6.4429 - val_binary_accuracy: 0.4902 - val_f1_score: 0.3604 - val_f1_flipped: 0.2927\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6687 - binary_accuracy: 0.5907 - f1_score: 0.3569 - f1_flipped: 0.3469 - val_loss: 6.4443 - val_binary_accuracy: 0.5022 - val_f1_score: 0.3769 - val_f1_flipped: 0.2879\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6653 - binary_accuracy: 0.5948 - f1_score: 0.3506 - f1_flipped: 0.3494 - val_loss: 6.8542 - val_binary_accuracy: 0.4746 - val_f1_score: 0.3567 - val_f1_flipped: 0.2810\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6604 - binary_accuracy: 0.6058 - f1_score: 0.3536 - f1_flipped: 0.3500 - val_loss: 6.7432 - val_binary_accuracy: 0.4821 - val_f1_score: 0.3505 - val_f1_flipped: 0.2923\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6595 - binary_accuracy: 0.6097 - f1_score: 0.3524 - f1_flipped: 0.3496 - val_loss: 6.3756 - val_binary_accuracy: 0.4987 - val_f1_score: 0.3703 - val_f1_flipped: 0.2862\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6535 - binary_accuracy: 0.6204 - f1_score: 0.3596 - f1_flipped: 0.3480 - val_loss: 6.5936 - val_binary_accuracy: 0.4871 - val_f1_score: 0.3672 - val_f1_flipped: 0.2795\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6456 - binary_accuracy: 0.6339 - f1_score: 0.3655 - f1_flipped: 0.3500 - val_loss: 7.1527 - val_binary_accuracy: 0.4554 - val_f1_score: 0.3569 - val_f1_flipped: 0.2594\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6478 - binary_accuracy: 0.6310 - f1_score: 0.3610 - f1_flipped: 0.3466 - val_loss: 7.0097 - val_binary_accuracy: 0.4946 - val_f1_score: 0.3814 - val_f1_flipped: 0.2679\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6339 - binary_accuracy: 0.6479 - f1_score: 0.3557 - f1_flipped: 0.3610 - val_loss: 5.8421 - val_binary_accuracy: 0.4719 - val_f1_score: 0.3834 - val_f1_flipped: 0.2355\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6402 - binary_accuracy: 0.6333 - f1_score: 0.3585 - f1_flipped: 0.3451 - val_loss: 6.2053 - val_binary_accuracy: 0.4437 - val_f1_score: 0.3900 - val_f1_flipped: 0.1931\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6240 - binary_accuracy: 0.6577 - f1_score: 0.3637 - f1_flipped: 0.3646 - val_loss: 4.2165 - val_binary_accuracy: 0.4513 - val_f1_score: 0.4243 - val_f1_flipped: 0.1479\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6212 - binary_accuracy: 0.6616 - f1_score: 0.3530 - f1_flipped: 0.3729 - val_loss: 4.6645 - val_binary_accuracy: 0.4942 - val_f1_score: 0.4332 - val_f1_flipped: 0.1736\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6245 - binary_accuracy: 0.6383 - f1_score: 0.3406 - f1_flipped: 0.3582 - val_loss: 4.7736 - val_binary_accuracy: 0.4951 - val_f1_score: 0.4371 - val_f1_flipped: 0.1678\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.2405 - binary_accuracy: 0.6452 - f1_score: 0.3443 - f1_flipped: 0.3597 - val_loss: 3.6442 - val_binary_accuracy: 0.5241 - val_f1_score: 0.4550 - val_f1_flipped: 0.1800\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.9946 - binary_accuracy: 0.6200 - f1_score: 0.3640 - f1_flipped: 0.3255 - val_loss: 5.2788 - val_binary_accuracy: 0.4741 - val_f1_score: 0.3892 - val_f1_flipped: 0.2340\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.0745 - binary_accuracy: 0.6133 - f1_score: 0.3391 - f1_flipped: 0.3472 - val_loss: 5.0096 - val_binary_accuracy: 0.4375 - val_f1_score: 0.3869 - val_f1_flipped: 0.1970\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 1.2053 - binary_accuracy: 0.5865 - f1_score: 0.3280 - f1_flipped: 0.3354 - val_loss: 4.2143 - val_binary_accuracy: 0.4960 - val_f1_score: 0.4263 - val_f1_flipped: 0.1912\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.9893 - binary_accuracy: 0.6079 - f1_score: 0.3422 - f1_flipped: 0.3335 - val_loss: 4.4153 - val_binary_accuracy: 0.4964 - val_f1_score: 0.4131 - val_f1_flipped: 0.2193\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.4277 - binary_accuracy: 0.5863 - f1_score: 0.3218 - f1_flipped: 0.3444 - val_loss: 7.0723 - val_binary_accuracy: 0.4103 - val_f1_score: 0.3711 - val_f1_flipped: 0.1822\n",
            "model trained in 108.993 seconds\n",
            "current cross-validation mean accuracy: 0.498, f1: 0.367, and f1 flipped: 0.203\n",
            "cross-validation total time: 109.334 seconds\n",
            "Xtrain shape (80, 112, 12)\n",
            "Xtest shape (20, 112, 12)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 5\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7055 - binary_accuracy: 0.4982 - f1_score: 0.3451 - f1_flipped: 0.3186 - val_loss: 7.9485 - val_binary_accuracy: 0.5027 - val_f1_score: 0.2864 - val_f1_flipped: 0.3815\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7029 - binary_accuracy: 0.5061 - f1_score: 0.3509 - f1_flipped: 0.3199 - val_loss: 7.9692 - val_binary_accuracy: 0.5013 - val_f1_score: 0.2873 - val_f1_flipped: 0.3797\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7008 - binary_accuracy: 0.5092 - f1_score: 0.3486 - f1_flipped: 0.3241 - val_loss: 8.0288 - val_binary_accuracy: 0.4973 - val_f1_score: 0.2873 - val_f1_flipped: 0.3757\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6985 - binary_accuracy: 0.5135 - f1_score: 0.3552 - f1_flipped: 0.3208 - val_loss: 7.5927 - val_binary_accuracy: 0.5188 - val_f1_score: 0.3009 - val_f1_flipped: 0.3817\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6956 - binary_accuracy: 0.5160 - f1_score: 0.3540 - f1_flipped: 0.3225 - val_loss: 8.0060 - val_binary_accuracy: 0.4982 - val_f1_score: 0.2861 - val_f1_flipped: 0.3782\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6939 - binary_accuracy: 0.5205 - f1_score: 0.3564 - f1_flipped: 0.3232 - val_loss: 7.8923 - val_binary_accuracy: 0.5049 - val_f1_score: 0.2891 - val_f1_flipped: 0.3804\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6926 - binary_accuracy: 0.5276 - f1_score: 0.3573 - f1_flipped: 0.3267 - val_loss: 7.8077 - val_binary_accuracy: 0.5098 - val_f1_score: 0.2914 - val_f1_flipped: 0.3832\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6889 - binary_accuracy: 0.5339 - f1_score: 0.3627 - f1_flipped: 0.3251 - val_loss: 7.8908 - val_binary_accuracy: 0.5000 - val_f1_score: 0.2882 - val_f1_flipped: 0.3774\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6898 - binary_accuracy: 0.5331 - f1_score: 0.3601 - f1_flipped: 0.3243 - val_loss: 7.8619 - val_binary_accuracy: 0.5058 - val_f1_score: 0.2926 - val_f1_flipped: 0.3784\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6860 - binary_accuracy: 0.5458 - f1_score: 0.3672 - f1_flipped: 0.3257 - val_loss: 7.7681 - val_binary_accuracy: 0.5112 - val_f1_score: 0.2950 - val_f1_flipped: 0.3809\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6840 - binary_accuracy: 0.5490 - f1_score: 0.3731 - f1_flipped: 0.3218 - val_loss: 7.6279 - val_binary_accuracy: 0.5045 - val_f1_score: 0.3025 - val_f1_flipped: 0.3674\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6803 - binary_accuracy: 0.5641 - f1_score: 0.3743 - f1_flipped: 0.3280 - val_loss: 7.5072 - val_binary_accuracy: 0.4996 - val_f1_score: 0.2884 - val_f1_flipped: 0.3763\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6794 - binary_accuracy: 0.5617 - f1_score: 0.3749 - f1_flipped: 0.3221 - val_loss: 7.6249 - val_binary_accuracy: 0.4884 - val_f1_score: 0.2870 - val_f1_flipped: 0.3669\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6783 - binary_accuracy: 0.5660 - f1_score: 0.3818 - f1_flipped: 0.3164 - val_loss: 6.6084 - val_binary_accuracy: 0.5085 - val_f1_score: 0.2846 - val_f1_flipped: 0.3846\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6737 - binary_accuracy: 0.5811 - f1_score: 0.3852 - f1_flipped: 0.3232 - val_loss: 6.9816 - val_binary_accuracy: 0.4920 - val_f1_score: 0.2955 - val_f1_flipped: 0.3602\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6735 - binary_accuracy: 0.5783 - f1_score: 0.3850 - f1_flipped: 0.3175 - val_loss: 5.9615 - val_binary_accuracy: 0.4862 - val_f1_score: 0.3027 - val_f1_flipped: 0.3421\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6730 - binary_accuracy: 0.5772 - f1_score: 0.3792 - f1_flipped: 0.3171 - val_loss: 4.9089 - val_binary_accuracy: 0.5107 - val_f1_score: 0.3397 - val_f1_flipped: 0.3167\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6703 - binary_accuracy: 0.5913 - f1_score: 0.3883 - f1_flipped: 0.3149 - val_loss: 3.9232 - val_binary_accuracy: 0.5094 - val_f1_score: 0.3402 - val_f1_flipped: 0.3104\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6682 - binary_accuracy: 0.5898 - f1_score: 0.3841 - f1_flipped: 0.3151 - val_loss: 3.3200 - val_binary_accuracy: 0.4844 - val_f1_score: 0.3332 - val_f1_flipped: 0.2875\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6610 - binary_accuracy: 0.6104 - f1_score: 0.3863 - f1_flipped: 0.3256 - val_loss: 3.5109 - val_binary_accuracy: 0.4424 - val_f1_score: 0.3342 - val_f1_flipped: 0.2421\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6613 - binary_accuracy: 0.6118 - f1_score: 0.3876 - f1_flipped: 0.3226 - val_loss: 2.5057 - val_binary_accuracy: 0.4277 - val_f1_score: 0.3413 - val_f1_flipped: 0.2097\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6649 - binary_accuracy: 0.5887 - f1_score: 0.3746 - f1_flipped: 0.3096 - val_loss: 2.1247 - val_binary_accuracy: 0.4201 - val_f1_score: 0.3406 - val_f1_flipped: 0.1923\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6558 - binary_accuracy: 0.6266 - f1_score: 0.3866 - f1_flipped: 0.3299 - val_loss: 1.7579 - val_binary_accuracy: 0.4353 - val_f1_score: 0.3629 - val_f1_flipped: 0.1758\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6548 - binary_accuracy: 0.6227 - f1_score: 0.3828 - f1_flipped: 0.3304 - val_loss: 1.2340 - val_binary_accuracy: 0.4647 - val_f1_score: 0.3897 - val_f1_flipped: 0.1667\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6550 - binary_accuracy: 0.6242 - f1_score: 0.3887 - f1_flipped: 0.3207 - val_loss: 1.0808 - val_binary_accuracy: 0.4795 - val_f1_score: 0.4036 - val_f1_flipped: 0.1540\n",
            "model trained in 107.977 seconds\n",
            "current cross-validation mean accuracy: 0.494, f1: 0.375, and f1 flipped: 0.193\n",
            "cross-validation total time: 108.322 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L7awQkiuTQl0",
        "colab_type": "code",
        "outputId": "27e73c34-8c7c-47f8-a7ca-1b2bad9d2efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "print(*results, sep='\\n')\n",
        "print('cross-validation mean accuracy: {:.3f}, f1: {:.3f}, and f1 flipped: {:.3f}'.format(\n",
        "       *[np.mean([r[key] for r in results]) for key in results[0].keys()]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'acc': 0.5200892686843872, 'F1': 0.3449758291244507, 'F1-flipped': 0.2288050651550293}\n",
            "{'acc': 0.4866071343421936, 'F1': 0.17573192715644836, 'F1-flipped': 0.3812209963798523}\n",
            "{'acc': 0.574999988079071, 'F1': 0.577412486076355, 'F1-flipped': 0.018581371754407883}\n",
            "{'acc': 0.4102678894996643, 'F1': 0.37114134430885315, 'F1-flipped': 0.1822464019060135}\n",
            "{'acc': 0.4794642925262451, 'F1': 0.4036409258842468, 'F1-flipped': 0.15399205684661865}\n",
            "cross-validation mean accuracy: 0.494, f1: 0.375, and f1 flipped: 0.193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cLxDiqS2ohuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5308
        },
        "outputId": "23f58101-941a-48a6-e2f2-6740016fa138"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test the model from the paper \"Confused or not confused\" with sub vectiors\n",
        "\"\"\"\n",
        "train_cols = orig_train_data_cols + vector_cols\n",
        "n_dim = len(train_cols)\n",
        "model, input_shape = get_model_timedist(min_intervals, n_dim)\n",
        "tpu_model = tpu_compatibilitate(model)\n",
        "\n",
        "results = cross_validate(model=tpu_model, X_shape=input_shape, data=dataset,\n",
        "                         time_distributed=True,\n",
        "                         intervals=min_intervals, even_data=truncate_data,\n",
        "                         n_test=2, verbose=1, epochs=25, batch_size=20)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain shape (80, 112, 24)\n",
            "Xtest shape (20, 112, 24)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 1\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 8s 94ms/step - loss: 0.7129 - binary_accuracy: 0.5092 - f1_score: 0.3591 - f1_flipped: 0.3122 - val_loss: 5.9852 - val_binary_accuracy: 0.5045 - val_f1_score: 0.2997 - val_f1_flipped: 0.3689\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6909 - binary_accuracy: 0.5432 - f1_score: 0.3775 - f1_flipped: 0.3199 - val_loss: 5.2081 - val_binary_accuracy: 0.5321 - val_f1_score: 0.2973 - val_f1_flipped: 0.3937\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6715 - binary_accuracy: 0.5805 - f1_score: 0.3972 - f1_flipped: 0.3221 - val_loss: 6.5863 - val_binary_accuracy: 0.4964 - val_f1_score: 0.3241 - val_f1_flipped: 0.3324\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6467 - binary_accuracy: 0.6230 - f1_score: 0.4214 - f1_flipped: 0.3250 - val_loss: 6.4106 - val_binary_accuracy: 0.4893 - val_f1_score: 0.3390 - val_f1_flipped: 0.3033\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7590 - binary_accuracy: 0.6718 - f1_score: 0.4271 - f1_flipped: 0.3434 - val_loss: 4.7576 - val_binary_accuracy: 0.4969 - val_f1_score: 0.3437 - val_f1_flipped: 0.3055\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5944 - binary_accuracy: 0.6720 - f1_score: 0.4171 - f1_flipped: 0.3477 - val_loss: 4.1453 - val_binary_accuracy: 0.5411 - val_f1_score: 0.3597 - val_f1_flipped: 0.3304\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.5720 - binary_accuracy: 0.7061 - f1_score: 0.4277 - f1_flipped: 0.3617 - val_loss: 3.4636 - val_binary_accuracy: 0.5723 - val_f1_score: 0.4015 - val_f1_flipped: 0.2982\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5565 - binary_accuracy: 0.7157 - f1_score: 0.4278 - f1_flipped: 0.3571 - val_loss: 2.3023 - val_binary_accuracy: 0.5746 - val_f1_score: 0.3984 - val_f1_flipped: 0.3020\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.5384 - binary_accuracy: 0.7229 - f1_score: 0.4330 - f1_flipped: 0.3587 - val_loss: 2.1563 - val_binary_accuracy: 0.5527 - val_f1_score: 0.4128 - val_f1_flipped: 0.2464\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5079 - binary_accuracy: 0.7493 - f1_score: 0.4345 - f1_flipped: 0.3744 - val_loss: 1.6330 - val_binary_accuracy: 0.5768 - val_f1_score: 0.4206 - val_f1_flipped: 0.2529\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5985 - binary_accuracy: 0.7408 - f1_score: 0.4385 - f1_flipped: 0.3585 - val_loss: 1.4068 - val_binary_accuracy: 0.5442 - val_f1_score: 0.4292 - val_f1_flipped: 0.1995\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.8528 - binary_accuracy: 0.7461 - f1_score: 0.4265 - f1_flipped: 0.3729 - val_loss: 1.2683 - val_binary_accuracy: 0.5058 - val_f1_score: 0.4288 - val_f1_flipped: 0.1527\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.8943 - binary_accuracy: 0.7383 - f1_score: 0.4240 - f1_flipped: 0.3733 - val_loss: 1.4201 - val_binary_accuracy: 0.4656 - val_f1_score: 0.4169 - val_f1_flipped: 0.1146\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6007 - binary_accuracy: 0.7615 - f1_score: 0.4352 - f1_flipped: 0.3826 - val_loss: 1.0500 - val_binary_accuracy: 0.4830 - val_f1_score: 0.4320 - val_f1_flipped: 0.1061\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 1.1276 - binary_accuracy: 0.7180 - f1_score: 0.4150 - f1_flipped: 0.3582 - val_loss: 1.4693 - val_binary_accuracy: 0.4656 - val_f1_score: 0.4147 - val_f1_flipped: 0.1087\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 1.3803 - binary_accuracy: 0.7429 - f1_score: 0.4182 - f1_flipped: 0.3823 - val_loss: 1.9635 - val_binary_accuracy: 0.4522 - val_f1_score: 0.4137 - val_f1_flipped: 0.0850\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.7036 - binary_accuracy: 0.6456 - f1_score: 0.3702 - f1_flipped: 0.3609 - val_loss: 2.0939 - val_binary_accuracy: 0.4388 - val_f1_score: 0.3967 - val_f1_flipped: 0.0996\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.7802 - binary_accuracy: 0.6401 - f1_score: 0.3672 - f1_flipped: 0.3513 - val_loss: 0.9597 - val_binary_accuracy: 0.4607 - val_f1_score: 0.4342 - val_f1_flipped: 0.0635\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.2937 - binary_accuracy: 0.6698 - f1_score: 0.3737 - f1_flipped: 0.3717 - val_loss: 1.6343 - val_binary_accuracy: 0.4134 - val_f1_score: 0.3974 - val_f1_flipped: 0.0609\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.0948 - binary_accuracy: 0.6710 - f1_score: 0.3880 - f1_flipped: 0.3564 - val_loss: 0.8535 - val_binary_accuracy: 0.4612 - val_f1_score: 0.4462 - val_f1_flipped: 0.0329\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.7356 - binary_accuracy: 0.7085 - f1_score: 0.4152 - f1_flipped: 0.3530 - val_loss: 0.8387 - val_binary_accuracy: 0.4589 - val_f1_score: 0.4460 - val_f1_flipped: 0.0301\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 1.9681 - binary_accuracy: 0.7010 - f1_score: 0.3855 - f1_flipped: 0.3754 - val_loss: 0.8206 - val_binary_accuracy: 0.4589 - val_f1_score: 0.4467 - val_f1_flipped: 0.0280\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 1.9339 - binary_accuracy: 0.7200 - f1_score: 0.4004 - f1_flipped: 0.3764 - val_loss: 0.8058 - val_binary_accuracy: 0.4549 - val_f1_score: 0.4462 - val_f1_flipped: 0.0225\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.0786 - binary_accuracy: 0.6977 - f1_score: 0.3906 - f1_flipped: 0.3688 - val_loss: 0.7929 - val_binary_accuracy: 0.4554 - val_f1_score: 0.4462 - val_f1_flipped: 0.0229\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.4626 - binary_accuracy: 0.6559 - f1_score: 0.3805 - f1_flipped: 0.3467 - val_loss: 0.7765 - val_binary_accuracy: 0.4741 - val_f1_score: 0.4428 - val_f1_flipped: 0.0493\n",
            "model trained in 113.329 seconds\n",
            "current cross-validation mean accuracy: 0.474, f1: 0.443, and f1 flipped: 0.049\n",
            "cross-validation total time: 113.670 seconds\n",
            "Xtrain shape (80, 112, 24)\n",
            "Xtest shape (20, 112, 24)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 2\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7131 - binary_accuracy: 0.5135 - f1_score: 0.3563 - f1_flipped: 0.3207 - val_loss: 6.6897 - val_binary_accuracy: 0.5018 - val_f1_score: 0.3459 - val_f1_flipped: 0.3205\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7089 - binary_accuracy: 0.5161 - f1_score: 0.3582 - f1_flipped: 0.3207 - val_loss: 5.8605 - val_binary_accuracy: 0.5107 - val_f1_score: 0.3330 - val_f1_flipped: 0.3415\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7044 - binary_accuracy: 0.5238 - f1_score: 0.3646 - f1_flipped: 0.3201 - val_loss: 5.5256 - val_binary_accuracy: 0.5071 - val_f1_score: 0.3397 - val_f1_flipped: 0.3301\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7038 - binary_accuracy: 0.5287 - f1_score: 0.3675 - f1_flipped: 0.3207 - val_loss: 5.4122 - val_binary_accuracy: 0.5152 - val_f1_score: 0.3433 - val_f1_flipped: 0.3340\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6969 - binary_accuracy: 0.5420 - f1_score: 0.3736 - f1_flipped: 0.3251 - val_loss: 5.8867 - val_binary_accuracy: 0.4888 - val_f1_score: 0.3370 - val_f1_flipped: 0.3167\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6961 - binary_accuracy: 0.5446 - f1_score: 0.3768 - f1_flipped: 0.3233 - val_loss: 5.4362 - val_binary_accuracy: 0.4558 - val_f1_score: 0.3252 - val_f1_flipped: 0.2967\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6922 - binary_accuracy: 0.5507 - f1_score: 0.3788 - f1_flipped: 0.3249 - val_loss: 4.9353 - val_binary_accuracy: 0.4437 - val_f1_score: 0.3200 - val_f1_flipped: 0.2905\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6867 - binary_accuracy: 0.5577 - f1_score: 0.3816 - f1_flipped: 0.3267 - val_loss: 3.5318 - val_binary_accuracy: 0.5036 - val_f1_score: 0.3345 - val_f1_flipped: 0.3286\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6837 - binary_accuracy: 0.5689 - f1_score: 0.3885 - f1_flipped: 0.3275 - val_loss: 2.4738 - val_binary_accuracy: 0.5246 - val_f1_score: 0.3312 - val_f1_flipped: 0.3468\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6786 - binary_accuracy: 0.5769 - f1_score: 0.3904 - f1_flipped: 0.3310 - val_loss: 2.0376 - val_binary_accuracy: 0.4915 - val_f1_score: 0.3091 - val_f1_flipped: 0.3360\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6779 - binary_accuracy: 0.5798 - f1_score: 0.3910 - f1_flipped: 0.3307 - val_loss: 1.7240 - val_binary_accuracy: 0.5134 - val_f1_score: 0.3106 - val_f1_flipped: 0.3496\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6774 - binary_accuracy: 0.5842 - f1_score: 0.3929 - f1_flipped: 0.3298 - val_loss: 1.3209 - val_binary_accuracy: 0.5004 - val_f1_score: 0.2955 - val_f1_flipped: 0.3531\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6671 - binary_accuracy: 0.6010 - f1_score: 0.3982 - f1_flipped: 0.3369 - val_loss: 1.2891 - val_binary_accuracy: 0.4844 - val_f1_score: 0.2742 - val_f1_flipped: 0.3550\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6697 - binary_accuracy: 0.6016 - f1_score: 0.4012 - f1_flipped: 0.3321 - val_loss: 0.9530 - val_binary_accuracy: 0.4875 - val_f1_score: 0.2540 - val_f1_flipped: 0.3710\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6650 - binary_accuracy: 0.6127 - f1_score: 0.4080 - f1_flipped: 0.3324 - val_loss: 0.7412 - val_binary_accuracy: 0.5080 - val_f1_score: 0.2678 - val_f1_flipped: 0.3736\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6607 - binary_accuracy: 0.6206 - f1_score: 0.4082 - f1_flipped: 0.3357 - val_loss: 0.7351 - val_binary_accuracy: 0.5085 - val_f1_score: 0.2677 - val_f1_flipped: 0.3712\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6528 - binary_accuracy: 0.6349 - f1_score: 0.4116 - f1_flipped: 0.3422 - val_loss: 0.7236 - val_binary_accuracy: 0.5121 - val_f1_score: 0.2633 - val_f1_flipped: 0.3731\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6832 - binary_accuracy: 0.6279 - f1_score: 0.4079 - f1_flipped: 0.3361 - val_loss: 0.7338 - val_binary_accuracy: 0.5076 - val_f1_score: 0.2549 - val_f1_flipped: 0.3732\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6473 - binary_accuracy: 0.6467 - f1_score: 0.4134 - f1_flipped: 0.3444 - val_loss: 0.7348 - val_binary_accuracy: 0.5121 - val_f1_score: 0.2509 - val_f1_flipped: 0.3750\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6369 - binary_accuracy: 0.6598 - f1_score: 0.4173 - f1_flipped: 0.3477 - val_loss: 0.7509 - val_binary_accuracy: 0.5112 - val_f1_score: 0.2432 - val_f1_flipped: 0.3747\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6430 - binary_accuracy: 0.6709 - f1_score: 0.4201 - f1_flipped: 0.3517 - val_loss: 0.7265 - val_binary_accuracy: 0.5080 - val_f1_score: 0.2237 - val_f1_flipped: 0.3767\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7176 - binary_accuracy: 0.6834 - f1_score: 0.4288 - f1_flipped: 0.3527 - val_loss: 0.7228 - val_binary_accuracy: 0.5058 - val_f1_score: 0.2134 - val_f1_flipped: 0.3766\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6394 - binary_accuracy: 0.6533 - f1_score: 0.4103 - f1_flipped: 0.3398 - val_loss: 0.7217 - val_binary_accuracy: 0.5058 - val_f1_score: 0.2081 - val_f1_flipped: 0.3764\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6166 - binary_accuracy: 0.6921 - f1_score: 0.4232 - f1_flipped: 0.3539 - val_loss: 0.7252 - val_binary_accuracy: 0.5067 - val_f1_score: 0.1973 - val_f1_flipped: 0.3763\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 0.6071 - binary_accuracy: 0.7012 - f1_score: 0.4257 - f1_flipped: 0.3541 - val_loss: 0.7304 - val_binary_accuracy: 0.5067 - val_f1_score: 0.1911 - val_f1_flipped: 0.3750\n",
            "model trained in 107.655 seconds\n",
            "current cross-validation mean accuracy: 0.490, f1: 0.317, and f1 flipped: 0.212\n",
            "cross-validation total time: 108.020 seconds\n",
            "Xtrain shape (80, 112, 24)\n",
            "Xtest shape (20, 112, 24)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 3\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7162 - binary_accuracy: 0.5078 - f1_score: 0.3330 - f1_flipped: 0.3389 - val_loss: 6.8070 - val_binary_accuracy: 0.5103 - val_f1_score: 0.4136 - val_f1_flipped: 0.2613\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7088 - binary_accuracy: 0.5205 - f1_score: 0.3396 - f1_flipped: 0.3428 - val_loss: 5.8237 - val_binary_accuracy: 0.4982 - val_f1_score: 0.3973 - val_f1_flipped: 0.2665\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7005 - binary_accuracy: 0.5309 - f1_score: 0.3435 - f1_flipped: 0.3473 - val_loss: 6.1144 - val_binary_accuracy: 0.4830 - val_f1_score: 0.3905 - val_f1_flipped: 0.2590\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6963 - binary_accuracy: 0.5371 - f1_score: 0.3447 - f1_flipped: 0.3490 - val_loss: 5.8205 - val_binary_accuracy: 0.4759 - val_f1_score: 0.3892 - val_f1_flipped: 0.2514\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6892 - binary_accuracy: 0.5529 - f1_score: 0.3503 - f1_flipped: 0.3559 - val_loss: 4.6010 - val_binary_accuracy: 0.4750 - val_f1_score: 0.3831 - val_f1_flipped: 0.2567\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6840 - binary_accuracy: 0.5637 - f1_score: 0.3552 - f1_flipped: 0.3577 - val_loss: 3.9676 - val_binary_accuracy: 0.4754 - val_f1_score: 0.3720 - val_f1_flipped: 0.2651\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7102 - binary_accuracy: 0.5691 - f1_score: 0.3548 - f1_flipped: 0.3607 - val_loss: 3.1509 - val_binary_accuracy: 0.5250 - val_f1_score: 0.4046 - val_f1_flipped: 0.2800\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6729 - binary_accuracy: 0.5835 - f1_score: 0.3592 - f1_flipped: 0.3648 - val_loss: 2.9343 - val_binary_accuracy: 0.5281 - val_f1_score: 0.4247 - val_f1_flipped: 0.2608\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6680 - binary_accuracy: 0.5962 - f1_score: 0.3590 - f1_flipped: 0.3707 - val_loss: 1.8518 - val_binary_accuracy: 0.5531 - val_f1_score: 0.4498 - val_f1_flipped: 0.2531\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6578 - binary_accuracy: 0.6150 - f1_score: 0.3671 - f1_flipped: 0.3743 - val_loss: 1.5412 - val_binary_accuracy: 0.5571 - val_f1_score: 0.4684 - val_f1_flipped: 0.2338\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6972 - binary_accuracy: 0.6239 - f1_score: 0.3649 - f1_flipped: 0.3791 - val_loss: 1.1128 - val_binary_accuracy: 0.5830 - val_f1_score: 0.4878 - val_f1_flipped: 0.2344\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6337 - binary_accuracy: 0.6472 - f1_score: 0.3765 - f1_flipped: 0.3820 - val_loss: 1.0705 - val_binary_accuracy: 0.5875 - val_f1_score: 0.5004 - val_f1_flipped: 0.2172\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6449 - binary_accuracy: 0.6488 - f1_score: 0.3649 - f1_flipped: 0.3874 - val_loss: 0.7668 - val_binary_accuracy: 0.6000 - val_f1_score: 0.5170 - val_f1_flipped: 0.2030\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6371 - binary_accuracy: 0.6579 - f1_score: 0.3669 - f1_flipped: 0.3892 - val_loss: 1.0220 - val_binary_accuracy: 0.5987 - val_f1_score: 0.5286 - val_f1_flipped: 0.1760\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6149 - binary_accuracy: 0.6907 - f1_score: 0.3759 - f1_flipped: 0.3999 - val_loss: 1.0328 - val_binary_accuracy: 0.6223 - val_f1_score: 0.5479 - val_f1_flipped: 0.1596\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6074 - binary_accuracy: 0.6953 - f1_score: 0.3691 - f1_flipped: 0.4002 - val_loss: 0.6768 - val_binary_accuracy: 0.6129 - val_f1_score: 0.5608 - val_f1_flipped: 0.1321\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6213 - binary_accuracy: 0.7131 - f1_score: 0.3758 - f1_flipped: 0.4049 - val_loss: 0.6653 - val_binary_accuracy: 0.6299 - val_f1_score: 0.5759 - val_f1_flipped: 0.1194\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5587 - binary_accuracy: 0.7119 - f1_score: 0.3718 - f1_flipped: 0.3990 - val_loss: 0.6606 - val_binary_accuracy: 0.6344 - val_f1_score: 0.5778 - val_f1_flipped: 0.1184\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 0.5488 - binary_accuracy: 0.7209 - f1_score: 0.3730 - f1_flipped: 0.3990 - val_loss: 0.6547 - val_binary_accuracy: 0.6406 - val_f1_score: 0.5838 - val_f1_flipped: 0.1112\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5201 - binary_accuracy: 0.7416 - f1_score: 0.3763 - f1_flipped: 0.4162 - val_loss: 0.6570 - val_binary_accuracy: 0.6362 - val_f1_score: 0.5876 - val_f1_flipped: 0.0939\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.5408 - binary_accuracy: 0.7261 - f1_score: 0.3689 - f1_flipped: 0.4069 - val_loss: 0.6549 - val_binary_accuracy: 0.6397 - val_f1_score: 0.5909 - val_f1_flipped: 0.0889\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.5878 - binary_accuracy: 0.7424 - f1_score: 0.3793 - f1_flipped: 0.4115 - val_loss: 0.6558 - val_binary_accuracy: 0.6353 - val_f1_score: 0.5895 - val_f1_flipped: 0.0855\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.5164 - binary_accuracy: 0.7644 - f1_score: 0.3909 - f1_flipped: 0.4166 - val_loss: 0.6650 - val_binary_accuracy: 0.6362 - val_f1_score: 0.5938 - val_f1_flipped: 0.0766\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.5176 - binary_accuracy: 0.7201 - f1_score: 0.3841 - f1_flipped: 0.3717 - val_loss: 0.6700 - val_binary_accuracy: 0.6388 - val_f1_score: 0.5940 - val_f1_flipped: 0.0791\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7952 - binary_accuracy: 0.7699 - f1_score: 0.3905 - f1_flipped: 0.4190 - val_loss: 0.6967 - val_binary_accuracy: 0.6308 - val_f1_score: 0.5921 - val_f1_flipped: 0.0724\n",
            "model trained in 108.005 seconds\n",
            "current cross-validation mean accuracy: 0.537, f1: 0.409, and f1 flipped: 0.166\n",
            "cross-validation total time: 108.369 seconds\n",
            "Xtrain shape (80, 112, 24)\n",
            "Xtest shape (20, 112, 24)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 4\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7139 - binary_accuracy: 0.5065 - f1_score: 0.3455 - f1_flipped: 0.3253 - val_loss: 6.3923 - val_binary_accuracy: 0.5031 - val_f1_score: 0.3642 - val_f1_flipped: 0.3034\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.8063 - binary_accuracy: 0.5124 - f1_score: 0.3458 - f1_flipped: 0.3293 - val_loss: 6.1351 - val_binary_accuracy: 0.5063 - val_f1_score: 0.3676 - val_f1_flipped: 0.3036\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7025 - binary_accuracy: 0.5251 - f1_score: 0.3508 - f1_flipped: 0.3351 - val_loss: 5.8660 - val_binary_accuracy: 0.4915 - val_f1_score: 0.3595 - val_f1_flipped: 0.2976\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6993 - binary_accuracy: 0.5326 - f1_score: 0.3570 - f1_flipped: 0.3344 - val_loss: 7.0135 - val_binary_accuracy: 0.4616 - val_f1_score: 0.3584 - val_f1_flipped: 0.2709\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.7386 - binary_accuracy: 0.5382 - f1_score: 0.3580 - f1_flipped: 0.3374 - val_loss: 5.5769 - val_binary_accuracy: 0.4991 - val_f1_score: 0.3736 - val_f1_flipped: 0.2896\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6890 - binary_accuracy: 0.5513 - f1_score: 0.3633 - f1_flipped: 0.3423 - val_loss: 5.6859 - val_binary_accuracy: 0.4746 - val_f1_score: 0.3583 - val_f1_flipped: 0.2836\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6845 - binary_accuracy: 0.5584 - f1_score: 0.3676 - f1_flipped: 0.3426 - val_loss: 5.5168 - val_binary_accuracy: 0.4978 - val_f1_score: 0.3615 - val_f1_flipped: 0.3003\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6796 - binary_accuracy: 0.5690 - f1_score: 0.3693 - f1_flipped: 0.3484 - val_loss: 4.8558 - val_binary_accuracy: 0.4835 - val_f1_score: 0.3713 - val_f1_flipped: 0.2766\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6763 - binary_accuracy: 0.5773 - f1_score: 0.3745 - f1_flipped: 0.3483 - val_loss: 4.9348 - val_binary_accuracy: 0.5103 - val_f1_score: 0.3799 - val_f1_flipped: 0.2926\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.6712 - binary_accuracy: 0.5844 - f1_score: 0.3737 - f1_flipped: 0.3521 - val_loss: 3.8704 - val_binary_accuracy: 0.5250 - val_f1_score: 0.3985 - val_f1_flipped: 0.2840\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.6672 - binary_accuracy: 0.5936 - f1_score: 0.3780 - f1_flipped: 0.3540 - val_loss: 2.9345 - val_binary_accuracy: 0.5433 - val_f1_score: 0.4174 - val_f1_flipped: 0.2789\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6664 - binary_accuracy: 0.5944 - f1_score: 0.3768 - f1_flipped: 0.3539 - val_loss: 3.2716 - val_binary_accuracy: 0.4951 - val_f1_score: 0.4066 - val_f1_flipped: 0.2449\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6591 - binary_accuracy: 0.6121 - f1_score: 0.3839 - f1_flipped: 0.3590 - val_loss: 2.4877 - val_binary_accuracy: 0.5232 - val_f1_score: 0.4267 - val_f1_flipped: 0.2472\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.6553 - binary_accuracy: 0.6189 - f1_score: 0.3842 - f1_flipped: 0.3619 - val_loss: 2.4709 - val_binary_accuracy: 0.5009 - val_f1_score: 0.4201 - val_f1_flipped: 0.2316\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6536 - binary_accuracy: 0.6290 - f1_score: 0.3907 - f1_flipped: 0.3624 - val_loss: 1.9044 - val_binary_accuracy: 0.5379 - val_f1_score: 0.4387 - val_f1_flipped: 0.2434\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6460 - binary_accuracy: 0.6363 - f1_score: 0.3887 - f1_flipped: 0.3663 - val_loss: 2.2403 - val_binary_accuracy: 0.5241 - val_f1_score: 0.4504 - val_f1_flipped: 0.2119\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.6420 - binary_accuracy: 0.6434 - f1_score: 0.3945 - f1_flipped: 0.3650 - val_loss: 1.6492 - val_binary_accuracy: 0.5469 - val_f1_score: 0.4631 - val_f1_flipped: 0.2141\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.6412 - binary_accuracy: 0.6452 - f1_score: 0.3906 - f1_flipped: 0.3667 - val_loss: 2.1938 - val_binary_accuracy: 0.4942 - val_f1_score: 0.4392 - val_f1_flipped: 0.1858\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6392 - binary_accuracy: 0.6546 - f1_score: 0.3917 - f1_flipped: 0.3699 - val_loss: 1.9030 - val_binary_accuracy: 0.5348 - val_f1_score: 0.4622 - val_f1_flipped: 0.1976\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6302 - binary_accuracy: 0.6598 - f1_score: 0.3955 - f1_flipped: 0.3705 - val_loss: 1.9308 - val_binary_accuracy: 0.5366 - val_f1_score: 0.4718 - val_f1_flipped: 0.1827\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6297 - binary_accuracy: 0.6641 - f1_score: 0.3930 - f1_flipped: 0.3741 - val_loss: 1.8329 - val_binary_accuracy: 0.5281 - val_f1_score: 0.4726 - val_f1_flipped: 0.1711\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6289 - binary_accuracy: 0.6658 - f1_score: 0.3940 - f1_flipped: 0.3691 - val_loss: 1.4815 - val_binary_accuracy: 0.5589 - val_f1_score: 0.4848 - val_f1_flipped: 0.1811\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.6322 - binary_accuracy: 0.6581 - f1_score: 0.3893 - f1_flipped: 0.3644 - val_loss: 1.5680 - val_binary_accuracy: 0.5536 - val_f1_score: 0.4766 - val_f1_flipped: 0.1813\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6166 - binary_accuracy: 0.6790 - f1_score: 0.3973 - f1_flipped: 0.3745 - val_loss: 1.5361 - val_binary_accuracy: 0.5571 - val_f1_score: 0.4905 - val_f1_flipped: 0.1651\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6201 - binary_accuracy: 0.6746 - f1_score: 0.3946 - f1_flipped: 0.3690 - val_loss: 1.5969 - val_binary_accuracy: 0.5420 - val_f1_score: 0.4751 - val_f1_flipped: 0.1656\n",
            "model trained in 111.038 seconds\n",
            "current cross-validation mean accuracy: 0.538, f1: 0.425, and f1 flipped: 0.166\n",
            "cross-validation total time: 111.376 seconds\n",
            "Xtrain shape (80, 112, 24)\n",
            "Xtest shape (20, 112, 24)\n",
            "ytrain shape (80, 112)\n",
            "ytest shape (20, 112)\n",
            "5-fold cross validation, iteration 5\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7364 - binary_accuracy: 0.5060 - f1_score: 0.3594 - f1_flipped: 0.3109 - val_loss: 6.4818 - val_binary_accuracy: 0.4902 - val_f1_score: 0.3031 - val_f1_flipped: 0.3539\n",
            "Epoch 2/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.7180 - binary_accuracy: 0.5177 - f1_score: 0.3688 - f1_flipped: 0.3110 - val_loss: 6.1482 - val_binary_accuracy: 0.5179 - val_f1_score: 0.3095 - val_f1_flipped: 0.3715\n",
            "Epoch 3/25\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 0.7361 - binary_accuracy: 0.5283 - f1_score: 0.3710 - f1_flipped: 0.3172 - val_loss: 5.6937 - val_binary_accuracy: 0.5228 - val_f1_score: 0.3105 - val_f1_flipped: 0.3741\n",
            "Epoch 4/25\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.7309 - binary_accuracy: 0.5295 - f1_score: 0.3728 - f1_flipped: 0.3159 - val_loss: 6.5619 - val_binary_accuracy: 0.5281 - val_f1_score: 0.3008 - val_f1_flipped: 0.3887\n",
            "Epoch 5/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7317 - binary_accuracy: 0.5422 - f1_score: 0.3816 - f1_flipped: 0.3164 - val_loss: 5.9060 - val_binary_accuracy: 0.5228 - val_f1_score: 0.3062 - val_f1_flipped: 0.3778\n",
            "Epoch 6/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6941 - binary_accuracy: 0.5474 - f1_score: 0.3854 - f1_flipped: 0.3160 - val_loss: 6.6556 - val_binary_accuracy: 0.4929 - val_f1_score: 0.2944 - val_f1_flipped: 0.3633\n",
            "Epoch 7/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.6874 - binary_accuracy: 0.5587 - f1_score: 0.3910 - f1_flipped: 0.3187 - val_loss: 4.4789 - val_binary_accuracy: 0.5402 - val_f1_score: 0.2974 - val_f1_flipped: 0.4011\n",
            "Epoch 8/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7134 - binary_accuracy: 0.5644 - f1_score: 0.3947 - f1_flipped: 0.3180 - val_loss: 3.8298 - val_binary_accuracy: 0.5179 - val_f1_score: 0.3071 - val_f1_flipped: 0.3713\n",
            "Epoch 9/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6770 - binary_accuracy: 0.5808 - f1_score: 0.4025 - f1_flipped: 0.3220 - val_loss: 3.4129 - val_binary_accuracy: 0.5317 - val_f1_score: 0.3059 - val_f1_flipped: 0.3822\n",
            "Epoch 10/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7273 - binary_accuracy: 0.5777 - f1_score: 0.4034 - f1_flipped: 0.3173 - val_loss: 2.8298 - val_binary_accuracy: 0.5165 - val_f1_score: 0.3138 - val_f1_flipped: 0.3604\n",
            "Epoch 11/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7404 - binary_accuracy: 0.5818 - f1_score: 0.4044 - f1_flipped: 0.3175 - val_loss: 2.4884 - val_binary_accuracy: 0.5125 - val_f1_score: 0.3211 - val_f1_flipped: 0.3472\n",
            "Epoch 12/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7457 - binary_accuracy: 0.5979 - f1_score: 0.4102 - f1_flipped: 0.3229 - val_loss: 2.6483 - val_binary_accuracy: 0.4982 - val_f1_score: 0.3196 - val_f1_flipped: 0.3370\n",
            "Epoch 13/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.8288 - binary_accuracy: 0.6017 - f1_score: 0.4098 - f1_flipped: 0.3249 - val_loss: 2.2995 - val_binary_accuracy: 0.4795 - val_f1_score: 0.3197 - val_f1_flipped: 0.3195\n",
            "Epoch 14/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7750 - binary_accuracy: 0.5944 - f1_score: 0.4123 - f1_flipped: 0.3144 - val_loss: 2.4404 - val_binary_accuracy: 0.4679 - val_f1_score: 0.3142 - val_f1_flipped: 0.3136\n",
            "Epoch 15/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.7345 - binary_accuracy: 0.6145 - f1_score: 0.4182 - f1_flipped: 0.3238 - val_loss: 2.2435 - val_binary_accuracy: 0.4746 - val_f1_score: 0.3269 - val_f1_flipped: 0.3045\n",
            "Epoch 16/25\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.7049 - binary_accuracy: 0.6177 - f1_score: 0.4233 - f1_flipped: 0.3185 - val_loss: 1.8447 - val_binary_accuracy: 0.4732 - val_f1_score: 0.3294 - val_f1_flipped: 0.2981\n",
            "Epoch 17/25\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.7461 - binary_accuracy: 0.6335 - f1_score: 0.4269 - f1_flipped: 0.3276 - val_loss: 1.4288 - val_binary_accuracy: 0.4844 - val_f1_score: 0.3411 - val_f1_flipped: 0.2921\n",
            "Epoch 18/25\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 0.7325 - binary_accuracy: 0.6333 - f1_score: 0.4267 - f1_flipped: 0.3259 - val_loss: 1.0327 - val_binary_accuracy: 0.4960 - val_f1_score: 0.3558 - val_f1_flipped: 0.2840\n",
            "Epoch 19/25\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 0.6674 - binary_accuracy: 0.6412 - f1_score: 0.4353 - f1_flipped: 0.3188 - val_loss: 1.0600 - val_binary_accuracy: 0.4969 - val_f1_score: 0.3572 - val_f1_flipped: 0.2807\n",
            "Epoch 20/25\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 0.7179 - binary_accuracy: 0.6432 - f1_score: 0.4317 - f1_flipped: 0.3238 - val_loss: 1.0605 - val_binary_accuracy: 0.5000 - val_f1_score: 0.3616 - val_f1_flipped: 0.2761\n",
            "Epoch 21/25\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.6783 - binary_accuracy: 0.6594 - f1_score: 0.4388 - f1_flipped: 0.3299 - val_loss: 0.8413 - val_binary_accuracy: 0.5054 - val_f1_score: 0.3681 - val_f1_flipped: 0.2713\n",
            "Epoch 22/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6792 - binary_accuracy: 0.6459 - f1_score: 0.4346 - f1_flipped: 0.3188 - val_loss: 0.6975 - val_binary_accuracy: 0.5103 - val_f1_score: 0.3727 - val_f1_flipped: 0.2688\n",
            "Epoch 23/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.6715 - binary_accuracy: 0.6653 - f1_score: 0.4413 - f1_flipped: 0.3267 - val_loss: 0.6952 - val_binary_accuracy: 0.5138 - val_f1_score: 0.3760 - val_f1_flipped: 0.2652\n",
            "Epoch 24/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.8188 - binary_accuracy: 0.6612 - f1_score: 0.4375 - f1_flipped: 0.3259 - val_loss: 0.8449 - val_binary_accuracy: 0.4996 - val_f1_score: 0.3672 - val_f1_flipped: 0.2599\n",
            "Epoch 25/25\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.8453 - binary_accuracy: 0.6657 - f1_score: 0.4395 - f1_flipped: 0.3246 - val_loss: 2.0840 - val_binary_accuracy: 0.4558 - val_f1_score: 0.3343 - val_f1_flipped: 0.2586\n",
            "model trained in 110.986 seconds\n",
            "current cross-validation mean accuracy: 0.522, f1: 0.407, and f1 flipped: 0.184\n",
            "cross-validation total time: 111.338 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0DUIzt97eVaM",
        "colab_type": "code",
        "outputId": "2f777188-3994-496c-c02a-9406bd9f0302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9792
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test mehmani model with subtitle vectors\n",
        "\"\"\"\n",
        "print(NormDataG.shape)\n",
        "train_cols = vector_cols\n",
        "n_dims = len(train_cols)\n",
        "model, input_shape = get_mehmani_model(max_intervals, n_dims)\n",
        "\n",
        "tpu_model = tpu_compatibilitate(model)\n",
        "results = cross_validate(model=tpu_model, X_shape=input_shape, data=NormDataG,\n",
        "                         intervals=max_intervals, even_data=zero_pad_data, n_test=2)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12811, 1039)\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 1\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 6s 79ms/step - loss: 0.6937 - acc: 0.5125 - f1_score: 0.1000 - f1_flipped: 0.4125 - val_loss: 0.6927 - val_acc: 0.5500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5500\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5125 - f1_score: 0.1125 - f1_flipped: 0.4000 - val_loss: 0.6929 - val_acc: 0.5500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5500\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6939 - acc: 0.4375 - f1_score: 0.2500 - f1_flipped: 0.1875 - val_loss: 0.6930 - val_acc: 0.5500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5500\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5250 - f1_score: 0.2875 - f1_flipped: 0.2375 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.4750 - f1_score: 0.2875 - f1_flipped: 0.1875 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6937 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6938 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6942 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6908 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6936 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6887 - acc: 0.5875 - f1_score: 0.5250 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6862 - acc: 0.5875 - f1_score: 0.4875 - f1_flipped: 0.1000 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5625 - f1_score: 0.4500 - f1_flipped: 0.1125 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6839 - acc: 0.5750 - f1_score: 0.4625 - f1_flipped: 0.1125 - val_loss: 0.6938 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6851 - acc: 0.6250 - f1_score: 0.4750 - f1_flipped: 0.1500 - val_loss: 0.6934 - val_acc: 0.4000 - val_f1_score: 0.4000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.6000 - f1_score: 0.4750 - f1_flipped: 0.1250 - val_loss: 0.6938 - val_acc: 0.4000 - val_f1_score: 0.4000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6739 - acc: 0.6750 - f1_score: 0.4875 - f1_flipped: 0.1875 - val_loss: 0.6952 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6776 - acc: 0.5375 - f1_score: 0.4500 - f1_flipped: 0.0875 - val_loss: 0.6962 - val_acc: 0.4000 - val_f1_score: 0.4000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.5500 - f1_score: 0.4625 - f1_flipped: 0.0875 - val_loss: 0.6948 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6691 - acc: 0.6750 - f1_score: 0.5000 - f1_flipped: 0.1750 - val_loss: 0.6934 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6875 - f1_score: 0.4500 - f1_flipped: 0.2375 - val_loss: 0.6936 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.7250 - f1_score: 0.4375 - f1_flipped: 0.2875 - val_loss: 0.6945 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6505 - acc: 0.6625 - f1_score: 0.4125 - f1_flipped: 0.2500 - val_loss: 0.6954 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6750 - f1_score: 0.4250 - f1_flipped: 0.2500 - val_loss: 0.6964 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.7500 - f1_score: 0.4375 - f1_flipped: 0.3125 - val_loss: 0.6930 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6438 - acc: 0.7000 - f1_score: 0.4125 - f1_flipped: 0.2875 - val_loss: 0.6981 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6269 - acc: 0.7500 - f1_score: 0.4500 - f1_flipped: 0.3000 - val_loss: 0.6989 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6114 - acc: 0.7375 - f1_score: 0.4500 - f1_flipped: 0.2875 - val_loss: 0.7148 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6078 - acc: 0.7125 - f1_score: 0.4625 - f1_flipped: 0.2500 - val_loss: 0.7032 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.7500 - f1_score: 0.4000 - f1_flipped: 0.3500 - val_loss: 0.6980 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6163 - acc: 0.7750 - f1_score: 0.4250 - f1_flipped: 0.3500 - val_loss: 0.7080 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6155 - acc: 0.7250 - f1_score: 0.4125 - f1_flipped: 0.3125 - val_loss: 0.7244 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6032 - acc: 0.7000 - f1_score: 0.4375 - f1_flipped: 0.2625 - val_loss: 0.7250 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6030 - acc: 0.7250 - f1_score: 0.4375 - f1_flipped: 0.2875 - val_loss: 0.7186 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5900 - acc: 0.7375 - f1_score: 0.4000 - f1_flipped: 0.3375 - val_loss: 0.7222 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5798 - acc: 0.7500 - f1_score: 0.4000 - f1_flipped: 0.3500 - val_loss: 0.7448 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5521 - acc: 0.7625 - f1_score: 0.4375 - f1_flipped: 0.3250 - val_loss: 0.7601 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5688 - acc: 0.7750 - f1_score: 0.4625 - f1_flipped: 0.3125 - val_loss: 0.7664 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5583 - acc: 0.7125 - f1_score: 0.4000 - f1_flipped: 0.3125 - val_loss: 0.7581 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5750 - acc: 0.7500 - f1_score: 0.4250 - f1_flipped: 0.3250 - val_loss: 0.7593 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5403 - acc: 0.7750 - f1_score: 0.4125 - f1_flipped: 0.3625 - val_loss: 0.7704 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5524 - acc: 0.7500 - f1_score: 0.4125 - f1_flipped: 0.3375 - val_loss: 0.7784 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5430 - acc: 0.7875 - f1_score: 0.4125 - f1_flipped: 0.3750 - val_loss: 0.8133 - val_acc: 0.4500 - val_f1_score: 0.3000 - val_f1_flipped: 0.1500\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5224 - acc: 0.7750 - f1_score: 0.4500 - f1_flipped: 0.3250 - val_loss: 0.8205 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5395 - acc: 0.7625 - f1_score: 0.4250 - f1_flipped: 0.3375 - val_loss: 0.8075 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5156 - acc: 0.7750 - f1_score: 0.4125 - f1_flipped: 0.3625 - val_loss: 0.7866 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5132 - acc: 0.8000 - f1_score: 0.4500 - f1_flipped: 0.3500 - val_loss: 0.8266 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5115 - acc: 0.7750 - f1_score: 0.4750 - f1_flipped: 0.3000 - val_loss: 0.8346 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "model trained in 17.571 seconds\n",
            "current cross-validation mean accuracy: 0.550, f1: 0.300, and f1 flipped: 0.250\n",
            "cross-validation total time: 17.588 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 2\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5875 - f1_score: 0.1375 - f1_flipped: 0.4500 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6952 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.4875 - f1_score: 0.0000e+00 - f1_flipped: 0.4875 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.5250 - f1_score: 0.0750 - f1_flipped: 0.4500 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5500 - f1_score: 0.1000 - f1_flipped: 0.4500 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.4000 - f1_score: 0.0875 - f1_flipped: 0.3125 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.4625 - f1_score: 0.1000 - f1_flipped: 0.3625 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5250 - f1_score: 0.1875 - f1_flipped: 0.3375 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6940 - acc: 0.4500 - f1_score: 0.1375 - f1_flipped: 0.3125 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.6000 - f1_score: 0.2500 - f1_flipped: 0.3500 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5625 - f1_score: 0.2375 - f1_flipped: 0.3250 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5750 - f1_score: 0.2875 - f1_flipped: 0.2875 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.2500 - val_f1_flipped: 0.2000\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6945 - acc: 0.4250 - f1_score: 0.2625 - f1_flipped: 0.1625 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.4625 - f1_score: 0.2250 - f1_flipped: 0.2375 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5125 - f1_score: 0.3125 - f1_flipped: 0.2000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5625 - f1_score: 0.3875 - f1_flipped: 0.1750 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.4875 - f1_score: 0.4000 - f1_flipped: 0.0875 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.5750 - f1_score: 0.4000 - f1_flipped: 0.1750 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.4875 - f1_score: 0.3000 - f1_flipped: 0.1875 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6944 - acc: 0.4500 - f1_score: 0.2625 - f1_flipped: 0.1875 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6940 - acc: 0.4500 - f1_score: 0.2500 - f1_flipped: 0.2000 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.4625 - f1_score: 0.2375 - f1_flipped: 0.2250 - val_loss: 0.6929 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.6000 - f1_score: 0.3250 - f1_flipped: 0.2750 - val_loss: 0.6929 - val_acc: 0.3500 - val_f1_score: 0.3500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5000 - f1_score: 0.3500 - f1_flipped: 0.1500 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5000 - f1_score: 0.3250 - f1_flipped: 0.1750 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6945 - acc: 0.4375 - f1_score: 0.2750 - f1_flipped: 0.1625 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.5000 - f1_score: 0.3000 - f1_flipped: 0.2000 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4125 - f1_score: 0.3000 - f1_flipped: 0.1125 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5250 - f1_score: 0.3750 - f1_flipped: 0.1500 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5125 - f1_score: 0.3375 - f1_flipped: 0.1750 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.4750 - f1_score: 0.2750 - f1_flipped: 0.2000 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5750 - f1_score: 0.3500 - f1_flipped: 0.2250 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5625 - f1_score: 0.4500 - f1_flipped: 0.1125 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5000 - f1_score: 0.4375 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5625 - f1_score: 0.4875 - f1_flipped: 0.0750 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5250 - f1_score: 0.4750 - f1_flipped: 0.0500 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6941 - acc: 0.4625 - f1_score: 0.4000 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5375 - f1_score: 0.4750 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.5125 - f1_score: 0.5000 - f1_flipped: 0.0125 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.5125 - f1_score: 0.4875 - f1_flipped: 0.0250 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5500 - f1_score: 0.5125 - f1_flipped: 0.0375 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.5375 - f1_score: 0.4250 - f1_flipped: 0.1125 - val_loss: 0.6924 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5875 - f1_score: 0.4375 - f1_flipped: 0.1500 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5250 - f1_score: 0.4000 - f1_flipped: 0.1250 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6896 - acc: 0.6250 - f1_score: 0.4625 - f1_flipped: 0.1625 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "model trained in 7.286 seconds\n",
            "current cross-validation mean accuracy: 0.525, f1: 0.400, and f1 flipped: 0.125\n",
            "cross-validation total time: 7.303 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 3\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5000 - f1_score: 0.2625 - f1_flipped: 0.2375 - val_loss: 0.6932 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5750 - f1_score: 0.2250 - f1_flipped: 0.3500 - val_loss: 0.6932 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5125 - f1_score: 0.1000 - f1_flipped: 0.4125 - val_loss: 0.6934 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4625 - f1_score: 0.0500 - f1_flipped: 0.4125 - val_loss: 0.6935 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.4750 - f1_score: 0.0250 - f1_flipped: 0.4500 - val_loss: 0.6939 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5375 - f1_score: 0.0500 - f1_flipped: 0.4875 - val_loss: 0.6944 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6948 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5375 - f1_score: 0.0250 - f1_flipped: 0.5125 - val_loss: 0.6945 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5000 - f1_score: 0.0500 - f1_flipped: 0.4500 - val_loss: 0.6943 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5625 - f1_score: 0.1875 - f1_flipped: 0.3750 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.3000 - val_f1_flipped: 0.1500\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.4875 - f1_score: 0.2625 - f1_flipped: 0.2250 - val_loss: 0.6928 - val_acc: 0.6000 - val_f1_score: 0.6000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.5125 - f1_score: 0.2875 - f1_flipped: 0.2250 - val_loss: 0.6930 - val_acc: 0.5500 - val_f1_score: 0.4000 - val_f1_flipped: 0.1500\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.4750 - f1_score: 0.2375 - f1_flipped: 0.2375 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6947 - acc: 0.4750 - f1_score: 0.2125 - f1_flipped: 0.2625 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4875 - f1_score: 0.2875 - f1_flipped: 0.2000 - val_loss: 0.6938 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5750 - f1_score: 0.2250 - f1_flipped: 0.3500 - val_loss: 0.6945 - val_acc: 0.4500 - val_f1_score: 0.1500 - val_f1_flipped: 0.3000\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.6250 - f1_score: 0.2375 - f1_flipped: 0.3875 - val_loss: 0.6948 - val_acc: 0.4500 - val_f1_score: 0.1500 - val_f1_flipped: 0.3000\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5500 - f1_score: 0.1500 - f1_flipped: 0.4000 - val_loss: 0.6947 - val_acc: 0.4000 - val_f1_score: 0.1500 - val_f1_flipped: 0.2500\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5125 - f1_score: 0.1375 - f1_flipped: 0.3750 - val_loss: 0.6953 - val_acc: 0.3500 - val_f1_score: 0.0500 - val_f1_flipped: 0.3000\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5750 - f1_score: 0.1500 - f1_flipped: 0.4250 - val_loss: 0.6958 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5375 - f1_score: 0.0625 - f1_flipped: 0.4750 - val_loss: 0.6961 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5500 - f1_score: 0.0875 - f1_flipped: 0.4625 - val_loss: 0.6957 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5500 - f1_score: 0.1250 - f1_flipped: 0.4250 - val_loss: 0.6963 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.5625 - f1_score: 0.1000 - f1_flipped: 0.4625 - val_loss: 0.6959 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6898 - acc: 0.5625 - f1_score: 0.1250 - f1_flipped: 0.4375 - val_loss: 0.6962 - val_acc: 0.3500 - val_f1_score: 0.0500 - val_f1_flipped: 0.3000\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.5125 - f1_score: 0.1500 - f1_flipped: 0.3625 - val_loss: 0.6956 - val_acc: 0.4000 - val_f1_score: 0.1500 - val_f1_flipped: 0.2500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6889 - acc: 0.6375 - f1_score: 0.2000 - f1_flipped: 0.4375 - val_loss: 0.6963 - val_acc: 0.4000 - val_f1_score: 0.1000 - val_f1_flipped: 0.3000\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5750 - f1_score: 0.1875 - f1_flipped: 0.3875 - val_loss: 0.6950 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.5625 - f1_score: 0.2125 - f1_flipped: 0.3500 - val_loss: 0.6948 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.5750 - f1_score: 0.2500 - f1_flipped: 0.3250 - val_loss: 0.6944 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6891 - acc: 0.5625 - f1_score: 0.2250 - f1_flipped: 0.3375 - val_loss: 0.6951 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.5250 - f1_score: 0.1875 - f1_flipped: 0.3375 - val_loss: 0.6971 - val_acc: 0.3000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3000\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.5875 - f1_score: 0.1625 - f1_flipped: 0.4250 - val_loss: 0.6993 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.5750 - f1_score: 0.0750 - f1_flipped: 0.5000 - val_loss: 0.7016 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.6000 - f1_score: 0.0875 - f1_flipped: 0.5125 - val_loss: 0.6998 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6901 - acc: 0.5625 - f1_score: 0.1000 - f1_flipped: 0.4625 - val_loss: 0.6987 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6862 - acc: 0.5625 - f1_score: 0.1375 - f1_flipped: 0.4250 - val_loss: 0.6984 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6874 - acc: 0.5625 - f1_score: 0.1375 - f1_flipped: 0.4250 - val_loss: 0.6965 - val_acc: 0.5000 - val_f1_score: 0.2000 - val_f1_flipped: 0.3000\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6879 - acc: 0.5500 - f1_score: 0.1875 - f1_flipped: 0.3625 - val_loss: 0.6959 - val_acc: 0.5000 - val_f1_score: 0.1500 - val_f1_flipped: 0.3500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6894 - acc: 0.6125 - f1_score: 0.1750 - f1_flipped: 0.4375 - val_loss: 0.6951 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6885 - acc: 0.5625 - f1_score: 0.2875 - f1_flipped: 0.2750 - val_loss: 0.6940 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6838 - acc: 0.6250 - f1_score: 0.2875 - f1_flipped: 0.3375 - val_loss: 0.6955 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6797 - acc: 0.6625 - f1_score: 0.3125 - f1_flipped: 0.3500 - val_loss: 0.6985 - val_acc: 0.4500 - val_f1_score: 0.1500 - val_f1_flipped: 0.3000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6775 - acc: 0.6500 - f1_score: 0.2000 - f1_flipped: 0.4500 - val_loss: 0.7001 - val_acc: 0.4500 - val_f1_score: 0.1000 - val_f1_flipped: 0.3500\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6808 - acc: 0.6250 - f1_score: 0.1375 - f1_flipped: 0.4875 - val_loss: 0.7021 - val_acc: 0.4000 - val_f1_score: 0.0500 - val_f1_flipped: 0.3500\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6768 - acc: 0.6250 - f1_score: 0.1250 - f1_flipped: 0.5000 - val_loss: 0.6995 - val_acc: 0.4500 - val_f1_score: 0.1000 - val_f1_flipped: 0.3500\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6772 - acc: 0.6875 - f1_score: 0.2625 - f1_flipped: 0.4250 - val_loss: 0.6959 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6761 - acc: 0.6625 - f1_score: 0.2875 - f1_flipped: 0.3750 - val_loss: 0.6926 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6723 - acc: 0.6500 - f1_score: 0.3000 - f1_flipped: 0.3500 - val_loss: 0.6960 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6752 - acc: 0.6500 - f1_score: 0.2125 - f1_flipped: 0.4375 - val_loss: 0.7014 - val_acc: 0.5000 - val_f1_score: 0.1500 - val_f1_flipped: 0.3500\n",
            "model trained in 7.178 seconds\n",
            "current cross-validation mean accuracy: 0.517, f1: 0.317, and f1 flipped: 0.200\n",
            "cross-validation total time: 7.197 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 4\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5875 - f1_score: 0.2125 - f1_flipped: 0.3750 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5125 - f1_score: 0.0750 - f1_flipped: 0.4375 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4500 - f1_score: 0.1375 - f1_flipped: 0.3125 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.2500 - val_f1_flipped: 0.2000\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5625 - f1_score: 0.3000 - f1_flipped: 0.2625 - val_loss: 0.6931 - val_acc: 0.6000 - val_f1_score: 0.5000 - val_f1_flipped: 0.1000\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5375 - f1_score: 0.2750 - f1_flipped: 0.2625 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5500 - f1_score: 0.1000 - f1_flipped: 0.4500 - val_loss: 0.6934 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4750 - f1_score: 0.0875 - f1_flipped: 0.3875 - val_loss: 0.6932 - val_acc: 0.5500 - val_f1_score: 0.2000 - val_f1_flipped: 0.3500\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5625 - f1_score: 0.2375 - f1_flipped: 0.3250 - val_loss: 0.6929 - val_acc: 0.5500 - val_f1_score: 0.5000 - val_f1_flipped: 0.0500\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.5000 - f1_score: 0.4250 - f1_flipped: 0.0750 - val_loss: 0.6924 - val_acc: 0.5500 - val_f1_score: 0.5500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5000 - f1_score: 0.4375 - f1_flipped: 0.0625 - val_loss: 0.6925 - val_acc: 0.5500 - val_f1_score: 0.5500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4625 - f1_score: 0.3750 - f1_flipped: 0.0875 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_score: 0.4500 - val_f1_flipped: 0.0500\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5375 - f1_score: 0.2500 - f1_flipped: 0.2875 - val_loss: 0.6938 - val_acc: 0.4000 - val_f1_score: 0.0500 - val_f1_flipped: 0.3500\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6895 - acc: 0.6000 - f1_score: 0.2250 - f1_flipped: 0.3750 - val_loss: 0.6940 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5750 - f1_score: 0.1125 - f1_flipped: 0.4625 - val_loss: 0.6947 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.5125 - f1_score: 0.0250 - f1_flipped: 0.4875 - val_loss: 0.6945 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5875 - f1_score: 0.1250 - f1_flipped: 0.4625 - val_loss: 0.6936 - val_acc: 0.5000 - val_f1_score: 0.1500 - val_f1_flipped: 0.3500\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6888 - acc: 0.6500 - f1_score: 0.1750 - f1_flipped: 0.4750 - val_loss: 0.6938 - val_acc: 0.5000 - val_f1_score: 0.1500 - val_f1_flipped: 0.3500\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.6625 - f1_score: 0.2625 - f1_flipped: 0.4000 - val_loss: 0.6936 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6890 - acc: 0.6500 - f1_score: 0.2875 - f1_flipped: 0.3625 - val_loss: 0.6930 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6879 - acc: 0.6250 - f1_score: 0.3125 - f1_flipped: 0.3125 - val_loss: 0.6936 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.6000 - f1_score: 0.2500 - f1_flipped: 0.3500 - val_loss: 0.6940 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6870 - acc: 0.5875 - f1_score: 0.1500 - f1_flipped: 0.4375 - val_loss: 0.6947 - val_acc: 0.5500 - val_f1_score: 0.1500 - val_f1_flipped: 0.4000\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6852 - acc: 0.5625 - f1_score: 0.1500 - f1_flipped: 0.4125 - val_loss: 0.6940 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.5750 - f1_score: 0.2875 - f1_flipped: 0.2875 - val_loss: 0.6926 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6889 - acc: 0.5375 - f1_score: 0.4250 - f1_flipped: 0.1125 - val_loss: 0.6922 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5625 - f1_score: 0.4125 - f1_flipped: 0.1500 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.5875 - f1_score: 0.2500 - f1_flipped: 0.3375 - val_loss: 0.6946 - val_acc: 0.5500 - val_f1_score: 0.2000 - val_f1_flipped: 0.3500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6793 - acc: 0.6000 - f1_score: 0.1625 - f1_flipped: 0.4375 - val_loss: 0.6932 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6804 - acc: 0.6375 - f1_score: 0.3000 - f1_flipped: 0.3375 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6772 - acc: 0.6250 - f1_score: 0.3125 - f1_flipped: 0.3125 - val_loss: 0.6913 - val_acc: 0.5500 - val_f1_score: 0.4000 - val_f1_flipped: 0.1500\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6725 - acc: 0.7500 - f1_score: 0.4250 - f1_flipped: 0.3250 - val_loss: 0.6908 - val_acc: 0.5000 - val_f1_score: 0.4500 - val_f1_flipped: 0.0500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6777 - acc: 0.5750 - f1_score: 0.3875 - f1_flipped: 0.1875 - val_loss: 0.6914 - val_acc: 0.5500 - val_f1_score: 0.4000 - val_f1_flipped: 0.1500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6695 - acc: 0.7125 - f1_score: 0.4000 - f1_flipped: 0.3125 - val_loss: 0.6907 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6690 - acc: 0.6375 - f1_score: 0.2500 - f1_flipped: 0.3875 - val_loss: 0.6911 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6610 - acc: 0.6875 - f1_score: 0.2750 - f1_flipped: 0.4125 - val_loss: 0.6897 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6639 - acc: 0.6500 - f1_score: 0.3125 - f1_flipped: 0.3375 - val_loss: 0.6887 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6575 - acc: 0.6750 - f1_score: 0.3375 - f1_flipped: 0.3375 - val_loss: 0.6889 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6604 - acc: 0.7000 - f1_score: 0.3625 - f1_flipped: 0.3375 - val_loss: 0.6888 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6568 - acc: 0.6750 - f1_score: 0.4000 - f1_flipped: 0.2750 - val_loss: 0.6878 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.7000 - f1_score: 0.3750 - f1_flipped: 0.3250 - val_loss: 0.6857 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6399 - acc: 0.7000 - f1_score: 0.3500 - f1_flipped: 0.3500 - val_loss: 0.6841 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.7125 - f1_score: 0.3500 - f1_flipped: 0.3625 - val_loss: 0.6810 - val_acc: 0.6500 - val_f1_score: 0.4500 - val_f1_flipped: 0.2000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6262 - acc: 0.7375 - f1_score: 0.4125 - f1_flipped: 0.3250 - val_loss: 0.6825 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6124 - acc: 0.7375 - f1_score: 0.4125 - f1_flipped: 0.3250 - val_loss: 0.6808 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6130 - acc: 0.7125 - f1_score: 0.3250 - f1_flipped: 0.3875 - val_loss: 0.6801 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6040 - acc: 0.7125 - f1_score: 0.3375 - f1_flipped: 0.3750 - val_loss: 0.6806 - val_acc: 0.7000 - val_f1_score: 0.4500 - val_f1_flipped: 0.2500\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6164 - acc: 0.6875 - f1_score: 0.4125 - f1_flipped: 0.2750 - val_loss: 0.6815 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5857 - acc: 0.7500 - f1_score: 0.4250 - f1_flipped: 0.3250 - val_loss: 0.6765 - val_acc: 0.7000 - val_f1_score: 0.4500 - val_f1_flipped: 0.2500\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5768 - acc: 0.7500 - f1_score: 0.3875 - f1_flipped: 0.3625 - val_loss: 0.6802 - val_acc: 0.6500 - val_f1_score: 0.3500 - val_f1_flipped: 0.3000\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5776 - acc: 0.7500 - f1_score: 0.4000 - f1_flipped: 0.3500 - val_loss: 0.6904 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "model trained in 7.105 seconds\n",
            "current cross-validation mean accuracy: 0.538, f1: 0.350, and f1 flipped: 0.188\n",
            "cross-validation total time: 7.120 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 5\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.6250 - f1_score: 0.4000 - f1_flipped: 0.2250 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5625 - f1_score: 0.5125 - f1_flipped: 0.0500 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5000 - f1_score: 0.5000 - f1_flipped: 0.0000e+00 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6939 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5125 - f1_score: 0.5125 - f1_flipped: 0.0000e+00 - val_loss: 0.6946 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6951 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6956 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6963 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6968 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6973 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6913 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6972 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6971 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6970 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6970 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6971 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6971 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6967 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5125 - f1_score: 0.5000 - f1_flipped: 0.0125 - val_loss: 0.6964 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6973 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6977 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6975 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6967 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6890 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6963 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6960 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6885 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6961 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6900 - acc: 0.5125 - f1_score: 0.4750 - f1_flipped: 0.0375 - val_loss: 0.6956 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6879 - acc: 0.5250 - f1_score: 0.4875 - f1_flipped: 0.0375 - val_loss: 0.6958 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5375 - f1_score: 0.5000 - f1_flipped: 0.0375 - val_loss: 0.6960 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6895 - acc: 0.5125 - f1_score: 0.5000 - f1_flipped: 0.0125 - val_loss: 0.6975 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6890 - acc: 0.5125 - f1_score: 0.5125 - f1_flipped: 0.0000e+00 - val_loss: 0.6978 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6882 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6976 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6971 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6966 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6889 - acc: 0.5625 - f1_score: 0.5125 - f1_flipped: 0.0500 - val_loss: 0.6955 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.5000 - f1_score: 0.4125 - f1_flipped: 0.0875 - val_loss: 0.6946 - val_acc: 0.5000 - val_f1_score: 0.4000 - val_f1_flipped: 0.1000\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6792 - acc: 0.6500 - f1_score: 0.5000 - f1_flipped: 0.1500 - val_loss: 0.6956 - val_acc: 0.5000 - val_f1_score: 0.4500 - val_f1_flipped: 0.0500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6849 - acc: 0.6875 - f1_score: 0.5000 - f1_flipped: 0.1875 - val_loss: 0.6951 - val_acc: 0.5000 - val_f1_score: 0.4000 - val_f1_flipped: 0.1000\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6753 - acc: 0.6750 - f1_score: 0.4875 - f1_flipped: 0.1875 - val_loss: 0.6956 - val_acc: 0.5000 - val_f1_score: 0.4000 - val_f1_flipped: 0.1000\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6761 - acc: 0.6250 - f1_score: 0.4875 - f1_flipped: 0.1375 - val_loss: 0.6972 - val_acc: 0.5000 - val_f1_score: 0.4500 - val_f1_flipped: 0.0500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6730 - acc: 0.6125 - f1_score: 0.5250 - f1_flipped: 0.0875 - val_loss: 0.6978 - val_acc: 0.5000 - val_f1_score: 0.4500 - val_f1_flipped: 0.0500\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6770 - acc: 0.6125 - f1_score: 0.4750 - f1_flipped: 0.1375 - val_loss: 0.6963 - val_acc: 0.6000 - val_f1_score: 0.4000 - val_f1_flipped: 0.2000\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6656 - acc: 0.7125 - f1_score: 0.4750 - f1_flipped: 0.2375 - val_loss: 0.6959 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6612 - acc: 0.6875 - f1_score: 0.4625 - f1_flipped: 0.2250 - val_loss: 0.6986 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6551 - acc: 0.6750 - f1_score: 0.4750 - f1_flipped: 0.2000 - val_loss: 0.7004 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.7250 - f1_score: 0.4750 - f1_flipped: 0.2500 - val_loss: 0.7007 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6875 - f1_score: 0.4500 - f1_flipped: 0.2375 - val_loss: 0.7017 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6396 - acc: 0.7625 - f1_score: 0.4375 - f1_flipped: 0.3250 - val_loss: 0.7073 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6440 - acc: 0.7000 - f1_score: 0.4625 - f1_flipped: 0.2375 - val_loss: 0.7113 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6379 - acc: 0.7250 - f1_score: 0.4625 - f1_flipped: 0.2625 - val_loss: 0.7156 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6164 - acc: 0.7875 - f1_score: 0.4500 - f1_flipped: 0.3375 - val_loss: 0.7168 - val_acc: 0.4000 - val_f1_score: 0.2000 - val_f1_flipped: 0.2000\n",
            "model trained in 7.128 seconds\n",
            "current cross-validation mean accuracy: 0.510, f1: 0.320, and f1 flipped: 0.190\n",
            "cross-validation total time: 7.145 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vwyd6soYf2BM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8ec66686-ef6e-49d2-83e5-4f161ce8a1f7"
      },
      "cell_type": "code",
      "source": [
        "print(*results, sep='\\n')\n",
        "print('cross-validation mean accuracy: {:.3f}, f1: {:.3f}, and f1 flipped: {:.3f}'.format(\n",
        "       *[np.mean([r[key] for r in results]) for key in results[0].keys()]))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'acc': 0.550000011920929, 'F1': 0.30000001192092896, 'F1-flipped': 0.25}\n",
            "{'acc': 0.5, 'F1': 0.5, 'F1-flipped': 0.0}\n",
            "{'acc': 0.5, 'F1': 0.15000000596046448, 'F1-flipped': 0.3499999940395355}\n",
            "{'acc': 0.6000000238418579, 'F1': 0.44999998807907104, 'F1-flipped': 0.15000000596046448}\n",
            "{'acc': 0.4000000059604645, 'F1': 0.20000000298023224, 'F1-flipped': 0.20000000298023224}\n",
            "cross-validation mean accuracy: 0.510, f1: 0.320, and f1 flipped: 0.190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ohrVgcUrisGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9774
        },
        "outputId": "d1e2b81e-5513-497b-83bf-cebb328f8b2c"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test paper model with subtitle vectors\n",
        "\"\"\"\n",
        "\n",
        "train_cols = vector_cols\n",
        "n_dims = len(train_cols)\n",
        "\n",
        "model, input_shape = get_mehmani_model(max_intervals, n_dims)\n",
        "\n",
        "tpu_model = tpu_compatibilitate(model)\n",
        "results = cross_validate(model=tpu_model, X_shape=input_shape, data=dataset,\n",
        "                         intervals=max_intervals, even_data=zero_pad_data, n_test=2)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 1\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 7s 84ms/step - loss: 0.6931 - acc: 0.5375 - f1_score: 0.3625 - f1_flipped: 0.1750 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5500 - f1_score: 0.3250 - f1_flipped: 0.2250 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5000 - f1_score: 0.3375 - f1_flipped: 0.1625 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5000 - f1_score: 0.4375 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6937 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6938 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6938 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.5250 - f1_score: 0.5000 - f1_flipped: 0.0250 - val_loss: 0.6930 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6881 - acc: 0.5375 - f1_score: 0.5125 - f1_flipped: 0.0250 - val_loss: 0.6949 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6855 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6918 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6835 - acc: 0.6000 - f1_score: 0.4375 - f1_flipped: 0.1625 - val_loss: 0.6896 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.6250 - f1_score: 0.4125 - f1_flipped: 0.2125 - val_loss: 0.6876 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6781 - acc: 0.6375 - f1_score: 0.4250 - f1_flipped: 0.2125 - val_loss: 0.6895 - val_acc: 0.5500 - val_f1_score: 0.4000 - val_f1_flipped: 0.1500\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6757 - acc: 0.6625 - f1_score: 0.4625 - f1_flipped: 0.2000 - val_loss: 0.6873 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6678 - acc: 0.7000 - f1_score: 0.4375 - f1_flipped: 0.2625 - val_loss: 0.6828 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6578 - acc: 0.7125 - f1_score: 0.4375 - f1_flipped: 0.2750 - val_loss: 0.6840 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6642 - acc: 0.6750 - f1_score: 0.4500 - f1_flipped: 0.2250 - val_loss: 0.6838 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6497 - acc: 0.7375 - f1_score: 0.4375 - f1_flipped: 0.3000 - val_loss: 0.6821 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6444 - acc: 0.7250 - f1_score: 0.4250 - f1_flipped: 0.3000 - val_loss: 0.6835 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6489 - acc: 0.7000 - f1_score: 0.4125 - f1_flipped: 0.2875 - val_loss: 0.6811 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.7375 - f1_score: 0.4250 - f1_flipped: 0.3125 - val_loss: 0.6819 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6296 - acc: 0.7375 - f1_score: 0.4000 - f1_flipped: 0.3375 - val_loss: 0.6868 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6206 - acc: 0.7375 - f1_score: 0.4125 - f1_flipped: 0.3250 - val_loss: 0.6954 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5968 - acc: 0.7625 - f1_score: 0.4250 - f1_flipped: 0.3375 - val_loss: 0.7017 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6098 - acc: 0.7250 - f1_score: 0.4125 - f1_flipped: 0.3125 - val_loss: 0.7050 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5988 - acc: 0.7500 - f1_score: 0.4000 - f1_flipped: 0.3500 - val_loss: 0.7105 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6039 - acc: 0.7500 - f1_score: 0.4125 - f1_flipped: 0.3375 - val_loss: 0.7104 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5930 - acc: 0.7500 - f1_score: 0.4250 - f1_flipped: 0.3250 - val_loss: 0.7118 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5741 - acc: 0.7625 - f1_score: 0.4125 - f1_flipped: 0.3500 - val_loss: 0.7181 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5564 - acc: 0.7875 - f1_score: 0.4125 - f1_flipped: 0.3750 - val_loss: 0.7275 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5707 - acc: 0.7500 - f1_score: 0.4125 - f1_flipped: 0.3375 - val_loss: 0.7394 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5472 - acc: 0.7875 - f1_score: 0.4125 - f1_flipped: 0.3750 - val_loss: 0.7517 - val_acc: 0.5000 - val_f1_score: 0.2500 - val_f1_flipped: 0.2500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.7875 - f1_score: 0.4125 - f1_flipped: 0.3750 - val_loss: 0.7563 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5580 - acc: 0.7625 - f1_score: 0.4250 - f1_flipped: 0.3375 - val_loss: 0.7470 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5417 - acc: 0.7500 - f1_score: 0.4125 - f1_flipped: 0.3375 - val_loss: 0.7536 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.7500 - f1_score: 0.3875 - f1_flipped: 0.3625 - val_loss: 0.7517 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5444 - acc: 0.7625 - f1_score: 0.4125 - f1_flipped: 0.3500 - val_loss: 0.7478 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5233 - acc: 0.7875 - f1_score: 0.4375 - f1_flipped: 0.3500 - val_loss: 0.7522 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5044 - acc: 0.8250 - f1_score: 0.4500 - f1_flipped: 0.3750 - val_loss: 0.7564 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5033 - acc: 0.8000 - f1_score: 0.4375 - f1_flipped: 0.3625 - val_loss: 0.7666 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5236 - acc: 0.8000 - f1_score: 0.4375 - f1_flipped: 0.3625 - val_loss: 0.7894 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4922 - acc: 0.8125 - f1_score: 0.4250 - f1_flipped: 0.3875 - val_loss: 0.8055 - val_acc: 0.5000 - val_f1_score: 0.2000 - val_f1_flipped: 0.3000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5369 - acc: 0.7750 - f1_score: 0.4000 - f1_flipped: 0.3750 - val_loss: 0.7967 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5115 - acc: 0.7750 - f1_score: 0.4250 - f1_flipped: 0.3500 - val_loss: 0.7877 - val_acc: 0.6500 - val_f1_score: 0.3500 - val_f1_flipped: 0.3000\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5078 - acc: 0.8000 - f1_score: 0.4500 - f1_flipped: 0.3500 - val_loss: 0.7789 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4964 - acc: 0.8125 - f1_score: 0.4375 - f1_flipped: 0.3750 - val_loss: 0.8195 - val_acc: 0.5000 - val_f1_score: 0.2000 - val_f1_flipped: 0.3000\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5206 - acc: 0.7875 - f1_score: 0.3875 - f1_flipped: 0.4000 - val_loss: 0.7935 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4996 - acc: 0.7875 - f1_score: 0.4125 - f1_flipped: 0.3750 - val_loss: 0.7882 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5064 - acc: 0.7875 - f1_score: 0.4625 - f1_flipped: 0.3250 - val_loss: 0.8033 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "model trained in 17.896 seconds\n",
            "current cross-validation mean accuracy: 0.600, f1: 0.300, and f1 flipped: 0.300\n",
            "cross-validation total time: 17.911 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 2\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5125 - f1_score: 0.2000 - f1_flipped: 0.3125 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4375 - f1_score: 0.1000 - f1_flipped: 0.3375 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5500 - f1_score: 0.1750 - f1_flipped: 0.3750 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5125 - f1_score: 0.2500 - f1_flipped: 0.2625 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6941 - acc: 0.4500 - f1_score: 0.2375 - f1_flipped: 0.2125 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5375 - f1_score: 0.2250 - f1_flipped: 0.3125 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.5000\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5250 - f1_score: 0.2250 - f1_flipped: 0.3000 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.6375 - f1_score: 0.2750 - f1_flipped: 0.3625 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5625 - f1_score: 0.2875 - f1_flipped: 0.2750 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5250 - f1_score: 0.3125 - f1_flipped: 0.2125 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.6125 - f1_score: 0.3000 - f1_flipped: 0.3125 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.5375 - f1_score: 0.2875 - f1_flipped: 0.2500 - val_loss: 0.6932 - val_acc: 0.4000 - val_f1_score: 0.4000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.6125 - f1_score: 0.4625 - f1_flipped: 0.1500 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.6250 - f1_score: 0.4375 - f1_flipped: 0.1875 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.6000 - f1_score: 0.5000 - f1_flipped: 0.1000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5500 - f1_score: 0.5000 - f1_flipped: 0.0500 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.5000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5750 - f1_score: 0.4375 - f1_flipped: 0.1375 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5625 - f1_score: 0.4250 - f1_flipped: 0.1375 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6901 - acc: 0.5875 - f1_score: 0.4250 - f1_flipped: 0.1625 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6892 - acc: 0.5750 - f1_score: 0.4500 - f1_flipped: 0.1250 - val_loss: 0.6932 - val_acc: 0.4000 - val_f1_score: 0.4000 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6884 - acc: 0.6125 - f1_score: 0.4125 - f1_flipped: 0.2000 - val_loss: 0.6931 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.6250 - f1_score: 0.3625 - f1_flipped: 0.2625 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4000 - val_f1_flipped: 0.0500\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.6875 - f1_score: 0.4250 - f1_flipped: 0.2625 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6869 - acc: 0.6625 - f1_score: 0.3625 - f1_flipped: 0.3000 - val_loss: 0.6930 - val_acc: 0.4500 - val_f1_score: 0.3000 - val_f1_flipped: 0.1500\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6844 - acc: 0.6250 - f1_score: 0.3250 - f1_flipped: 0.3000 - val_loss: 0.6930 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6874 - acc: 0.6250 - f1_score: 0.3750 - f1_flipped: 0.2500 - val_loss: 0.6930 - val_acc: 0.4000 - val_f1_score: 0.3500 - val_f1_flipped: 0.0500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6848 - acc: 0.5875 - f1_score: 0.3375 - f1_flipped: 0.2500 - val_loss: 0.6928 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6870 - acc: 0.5625 - f1_score: 0.3750 - f1_flipped: 0.1875 - val_loss: 0.6928 - val_acc: 0.6000 - val_f1_score: 0.3500 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6799 - acc: 0.7000 - f1_score: 0.3875 - f1_flipped: 0.3125 - val_loss: 0.6928 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6125 - f1_score: 0.3750 - f1_flipped: 0.2375 - val_loss: 0.6928 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6837 - acc: 0.6875 - f1_score: 0.4250 - f1_flipped: 0.2625 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6819 - acc: 0.6375 - f1_score: 0.4125 - f1_flipped: 0.2250 - val_loss: 0.6926 - val_acc: 0.5500 - val_f1_score: 0.4000 - val_f1_flipped: 0.1500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6794 - acc: 0.6500 - f1_score: 0.4500 - f1_flipped: 0.2000 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6755 - acc: 0.6500 - f1_score: 0.4375 - f1_flipped: 0.2125 - val_loss: 0.6924 - val_acc: 0.5000 - val_f1_score: 0.3500 - val_f1_flipped: 0.1500\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6746 - acc: 0.6875 - f1_score: 0.4125 - f1_flipped: 0.2750 - val_loss: 0.6921 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6712 - acc: 0.7000 - f1_score: 0.4125 - f1_flipped: 0.2875 - val_loss: 0.6917 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6788 - acc: 0.6875 - f1_score: 0.3500 - f1_flipped: 0.3375 - val_loss: 0.6910 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6751 - acc: 0.7250 - f1_score: 0.4000 - f1_flipped: 0.3250 - val_loss: 0.6911 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6684 - acc: 0.6750 - f1_score: 0.3875 - f1_flipped: 0.2875 - val_loss: 0.6911 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6723 - acc: 0.7125 - f1_score: 0.4125 - f1_flipped: 0.3000 - val_loss: 0.6914 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6599 - acc: 0.7250 - f1_score: 0.4000 - f1_flipped: 0.3250 - val_loss: 0.6912 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6609 - acc: 0.7250 - f1_score: 0.4250 - f1_flipped: 0.3000 - val_loss: 0.6914 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6606 - acc: 0.6875 - f1_score: 0.4000 - f1_flipped: 0.2875 - val_loss: 0.6919 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.7125 - f1_score: 0.4625 - f1_flipped: 0.2500 - val_loss: 0.6911 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6641 - acc: 0.6125 - f1_score: 0.3875 - f1_flipped: 0.2250 - val_loss: 0.6905 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.7000 - f1_score: 0.4250 - f1_flipped: 0.2750 - val_loss: 0.6907 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.7125 - f1_score: 0.3750 - f1_flipped: 0.3375 - val_loss: 0.6900 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6565 - acc: 0.6125 - f1_score: 0.3250 - f1_flipped: 0.2875 - val_loss: 0.6901 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6573 - acc: 0.6625 - f1_score: 0.3500 - f1_flipped: 0.3125 - val_loss: 0.6921 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6366 - acc: 0.6875 - f1_score: 0.4500 - f1_flipped: 0.2375 - val_loss: 0.6944 - val_acc: 0.4500 - val_f1_score: 0.3000 - val_f1_flipped: 0.1500\n",
            "model trained in 7.223 seconds\n",
            "current cross-validation mean accuracy: 0.525, f1: 0.300, and f1 flipped: 0.225\n",
            "cross-validation total time: 7.237 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 3\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5750 - f1_score: 0.3375 - f1_flipped: 0.2375 - val_loss: 0.6932 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4250 - f1_score: 0.0875 - f1_flipped: 0.3375 - val_loss: 0.6934 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5250 - f1_score: 0.0375 - f1_flipped: 0.4875 - val_loss: 0.6934 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5375 - f1_score: 0.0375 - f1_flipped: 0.5000 - val_loss: 0.6935 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5250 - f1_score: 0.0125 - f1_flipped: 0.5125 - val_loss: 0.6936 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6938 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6939 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6941 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6941 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6941 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6941 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6942 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6945 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6944 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6944 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6945 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5250 - f1_score: 0.0125 - f1_flipped: 0.5125 - val_loss: 0.6947 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6948 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5125 - f1_score: 0.0000e+00 - f1_flipped: 0.5125 - val_loss: 0.6948 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5500 - f1_score: 0.0375 - f1_flipped: 0.5125 - val_loss: 0.6948 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5375 - f1_score: 0.0250 - f1_flipped: 0.5125 - val_loss: 0.6947 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.4875 - f1_score: 0.0125 - f1_flipped: 0.4750 - val_loss: 0.6949 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.5625 - f1_score: 0.0500 - f1_flipped: 0.5125 - val_loss: 0.6952 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6892 - acc: 0.5250 - f1_score: 0.0125 - f1_flipped: 0.5125 - val_loss: 0.6955 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.5250 - f1_score: 0.0375 - f1_flipped: 0.4875 - val_loss: 0.6958 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.5750 - f1_score: 0.0625 - f1_flipped: 0.5125 - val_loss: 0.6957 - val_acc: 0.4000 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4000\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.5750 - f1_score: 0.1000 - f1_flipped: 0.4750 - val_loss: 0.6949 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6885 - acc: 0.6000 - f1_score: 0.1500 - f1_flipped: 0.4500 - val_loss: 0.6944 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6894 - acc: 0.5875 - f1_score: 0.1375 - f1_flipped: 0.4500 - val_loss: 0.6945 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6877 - acc: 0.6500 - f1_score: 0.1625 - f1_flipped: 0.4875 - val_loss: 0.6947 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.6000 - f1_score: 0.1375 - f1_flipped: 0.4625 - val_loss: 0.6953 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.5875 - f1_score: 0.1000 - f1_flipped: 0.4875 - val_loss: 0.6961 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6894 - acc: 0.6125 - f1_score: 0.1250 - f1_flipped: 0.4875 - val_loss: 0.6958 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.5875 - f1_score: 0.1125 - f1_flipped: 0.4750 - val_loss: 0.6952 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6823 - acc: 0.6125 - f1_score: 0.1750 - f1_flipped: 0.4375 - val_loss: 0.6951 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6836 - acc: 0.6000 - f1_score: 0.1375 - f1_flipped: 0.4625 - val_loss: 0.6959 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6770 - acc: 0.6375 - f1_score: 0.1500 - f1_flipped: 0.4875 - val_loss: 0.6950 - val_acc: 0.4000 - val_f1_score: 0.0500 - val_f1_flipped: 0.3500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6819 - acc: 0.6375 - f1_score: 0.2000 - f1_flipped: 0.4375 - val_loss: 0.6949 - val_acc: 0.4000 - val_f1_score: 0.0500 - val_f1_flipped: 0.3500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6375 - f1_score: 0.1375 - f1_flipped: 0.5000 - val_loss: 0.6970 - val_acc: 0.3500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.3500\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6798 - acc: 0.6625 - f1_score: 0.1750 - f1_flipped: 0.4875 - val_loss: 0.6959 - val_acc: 0.4000 - val_f1_score: 0.0500 - val_f1_flipped: 0.3500\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6823 - acc: 0.5875 - f1_score: 0.1875 - f1_flipped: 0.4000 - val_loss: 0.6932 - val_acc: 0.5500 - val_f1_score: 0.2000 - val_f1_flipped: 0.3500\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6816 - acc: 0.5625 - f1_score: 0.2000 - f1_flipped: 0.3625 - val_loss: 0.6900 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6740 - acc: 0.6375 - f1_score: 0.2750 - f1_flipped: 0.3625 - val_loss: 0.6909 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6756 - acc: 0.6375 - f1_score: 0.3000 - f1_flipped: 0.3375 - val_loss: 0.6896 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6697 - acc: 0.6875 - f1_score: 0.2875 - f1_flipped: 0.4000 - val_loss: 0.6900 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6667 - acc: 0.6625 - f1_score: 0.2250 - f1_flipped: 0.4375 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.1000 - val_f1_flipped: 0.3500\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6712 - acc: 0.5875 - f1_score: 0.1750 - f1_flipped: 0.4125 - val_loss: 0.6955 - val_acc: 0.4500 - val_f1_score: 0.1000 - val_f1_flipped: 0.3500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.6250 - f1_score: 0.2375 - f1_flipped: 0.3875 - val_loss: 0.6895 - val_acc: 0.5000 - val_f1_score: 0.2000 - val_f1_flipped: 0.3000\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6609 - acc: 0.6625 - f1_score: 0.2500 - f1_flipped: 0.4125 - val_loss: 0.6838 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6635 - acc: 0.6375 - f1_score: 0.2500 - f1_flipped: 0.3875 - val_loss: 0.6852 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "model trained in 7.205 seconds\n",
            "current cross-validation mean accuracy: 0.533, f1: 0.283, and f1 flipped: 0.250\n",
            "cross-validation total time: 7.232 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 4\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4875 - f1_score: 0.2000 - f1_flipped: 0.2875 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5500 - f1_score: 0.1125 - f1_flipped: 0.4375 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.4500 - f1_score: 0.0750 - f1_flipped: 0.3750 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5500 - f1_score: 0.1500 - f1_flipped: 0.4000 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5625 - f1_score: 0.1500 - f1_flipped: 0.4125 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6939 - acc: 0.5125 - f1_score: 0.1375 - f1_flipped: 0.3750 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.5125 - f1_score: 0.0750 - f1_flipped: 0.4375 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5250 - f1_score: 0.1375 - f1_flipped: 0.3875 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.4250 - f1_score: 0.1000 - f1_flipped: 0.3250 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6921 - acc: 0.5125 - f1_score: 0.1250 - f1_flipped: 0.3875 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5250 - f1_score: 0.1375 - f1_flipped: 0.3875 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5375 - f1_score: 0.1125 - f1_flipped: 0.4250 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5250 - f1_score: 0.1000 - f1_flipped: 0.4250 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4375 - f1_score: 0.0625 - f1_flipped: 0.3750 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5375 - f1_score: 0.0625 - f1_flipped: 0.4750 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5125 - f1_score: 0.0875 - f1_flipped: 0.4250 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.5125 - f1_score: 0.0750 - f1_flipped: 0.4375 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.4875 - f1_score: 0.0500 - f1_flipped: 0.4375 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.5500 - f1_score: 0.0875 - f1_flipped: 0.4625 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5250 - f1_score: 0.0750 - f1_flipped: 0.4500 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.5875 - f1_score: 0.1875 - f1_flipped: 0.4000 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.0000e+00 - val_f1_flipped: 0.4500\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.5875 - f1_score: 0.1750 - f1_flipped: 0.4125 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_score: 0.1500 - val_f1_flipped: 0.3500\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6898 - acc: 0.6125 - f1_score: 0.2000 - f1_flipped: 0.4125 - val_loss: 0.6932 - val_acc: 0.5500 - val_f1_score: 0.2000 - val_f1_flipped: 0.3500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6894 - acc: 0.6000 - f1_score: 0.2000 - f1_flipped: 0.4000 - val_loss: 0.6931 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6887 - acc: 0.6250 - f1_score: 0.2875 - f1_flipped: 0.3375 - val_loss: 0.6929 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6891 - acc: 0.6000 - f1_score: 0.3125 - f1_flipped: 0.2875 - val_loss: 0.6929 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6879 - acc: 0.6375 - f1_score: 0.3250 - f1_flipped: 0.3125 - val_loss: 0.6928 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6888 - acc: 0.5375 - f1_score: 0.2875 - f1_flipped: 0.2500 - val_loss: 0.6928 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6862 - acc: 0.6000 - f1_score: 0.2750 - f1_flipped: 0.3250 - val_loss: 0.6927 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6854 - acc: 0.6375 - f1_score: 0.3125 - f1_flipped: 0.3250 - val_loss: 0.6925 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6847 - acc: 0.6625 - f1_score: 0.3125 - f1_flipped: 0.3500 - val_loss: 0.6924 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6857 - acc: 0.6000 - f1_score: 0.3000 - f1_flipped: 0.3000 - val_loss: 0.6922 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6866 - acc: 0.6625 - f1_score: 0.3500 - f1_flipped: 0.3125 - val_loss: 0.6918 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6827 - acc: 0.6250 - f1_score: 0.3125 - f1_flipped: 0.3125 - val_loss: 0.6920 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6788 - acc: 0.6625 - f1_score: 0.2875 - f1_flipped: 0.3750 - val_loss: 0.6920 - val_acc: 0.5500 - val_f1_score: 0.2500 - val_f1_flipped: 0.3000\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6785 - acc: 0.6625 - f1_score: 0.2875 - f1_flipped: 0.3750 - val_loss: 0.6914 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6797 - acc: 0.6500 - f1_score: 0.3250 - f1_flipped: 0.3250 - val_loss: 0.6909 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6694 - acc: 0.7000 - f1_score: 0.3625 - f1_flipped: 0.3375 - val_loss: 0.6907 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6754 - acc: 0.6125 - f1_score: 0.2625 - f1_flipped: 0.3500 - val_loss: 0.6899 - val_acc: 0.6500 - val_f1_score: 0.3500 - val_f1_flipped: 0.3000\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.6625 - f1_score: 0.3375 - f1_flipped: 0.3250 - val_loss: 0.6887 - val_acc: 0.6500 - val_f1_score: 0.3500 - val_f1_flipped: 0.3000\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6604 - acc: 0.7125 - f1_score: 0.3625 - f1_flipped: 0.3500 - val_loss: 0.6859 - val_acc: 0.6000 - val_f1_score: 0.4000 - val_f1_flipped: 0.2000\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6687 - acc: 0.6625 - f1_score: 0.3375 - f1_flipped: 0.3250 - val_loss: 0.6844 - val_acc: 0.6000 - val_f1_score: 0.4000 - val_f1_flipped: 0.2000\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6592 - acc: 0.6750 - f1_score: 0.3875 - f1_flipped: 0.2875 - val_loss: 0.6840 - val_acc: 0.6000 - val_f1_score: 0.4000 - val_f1_flipped: 0.2000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6517 - acc: 0.7375 - f1_score: 0.3750 - f1_flipped: 0.3625 - val_loss: 0.6833 - val_acc: 0.6500 - val_f1_score: 0.3500 - val_f1_flipped: 0.3000\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6571 - acc: 0.6500 - f1_score: 0.2375 - f1_flipped: 0.4125 - val_loss: 0.6839 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6674 - acc: 0.6000 - f1_score: 0.3125 - f1_flipped: 0.2875 - val_loss: 0.6816 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6574 - acc: 0.6625 - f1_score: 0.4625 - f1_flipped: 0.2000 - val_loss: 0.6816 - val_acc: 0.6000 - val_f1_score: 0.4500 - val_f1_flipped: 0.1500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6490 - acc: 0.6750 - f1_score: 0.4250 - f1_flipped: 0.2500 - val_loss: 0.6809 - val_acc: 0.6500 - val_f1_score: 0.4000 - val_f1_flipped: 0.2500\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6388 - acc: 0.6375 - f1_score: 0.3000 - f1_flipped: 0.3375 - val_loss: 0.6825 - val_acc: 0.6000 - val_f1_score: 0.3000 - val_f1_flipped: 0.3000\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6750 - f1_score: 0.3750 - f1_flipped: 0.3000 - val_loss: 0.6773 - val_acc: 0.6000 - val_f1_score: 0.4000 - val_f1_flipped: 0.2000\n",
            "model trained in 7.156 seconds\n",
            "current cross-validation mean accuracy: 0.550, f1: 0.313, and f1 flipped: 0.238\n",
            "cross-validation total time: 7.174 seconds\n",
            "Xtrain shape (80, 1, 144, 12, 1)\n",
            "Xtest shape (20, 1, 144, 12, 1)\n",
            "ytrain shape (80,)\n",
            "ytest shape (20,)\n",
            "5-fold cross validation, iteration 5\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5000 - f1_score: 0.3875 - f1_flipped: 0.1125 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4500 - f1_score: 0.3500 - f1_flipped: 0.1000 - val_loss: 0.6932 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.6125 - f1_score: 0.4375 - f1_flipped: 0.1750 - val_loss: 0.6933 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.5000 - f1_score: 0.3875 - f1_flipped: 0.1125 - val_loss: 0.6934 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5375 - f1_score: 0.4750 - f1_flipped: 0.0625 - val_loss: 0.6935 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5375 - f1_score: 0.4500 - f1_flipped: 0.0875 - val_loss: 0.6937 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6939 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5250 - f1_score: 0.5250 - f1_flipped: 0.0000e+00 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6940 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6885 - acc: 0.6250 - f1_score: 0.4875 - f1_flipped: 0.1375 - val_loss: 0.6942 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.6000 - f1_score: 0.4875 - f1_flipped: 0.1125 - val_loss: 0.6941 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.5625 - f1_score: 0.4000 - f1_flipped: 0.1625 - val_loss: 0.6942 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6901 - acc: 0.6250 - f1_score: 0.4250 - f1_flipped: 0.2000 - val_loss: 0.6944 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.6250 - f1_score: 0.4500 - f1_flipped: 0.1750 - val_loss: 0.6947 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6900 - acc: 0.5875 - f1_score: 0.5125 - f1_flipped: 0.0750 - val_loss: 0.6948 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.6125 - f1_score: 0.5125 - f1_flipped: 0.1000 - val_loss: 0.6950 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6854 - acc: 0.5750 - f1_score: 0.5250 - f1_flipped: 0.0500 - val_loss: 0.6953 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6880 - acc: 0.5375 - f1_score: 0.5250 - f1_flipped: 0.0125 - val_loss: 0.6955 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6851 - acc: 0.5625 - f1_score: 0.5250 - f1_flipped: 0.0375 - val_loss: 0.6956 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6826 - acc: 0.5625 - f1_score: 0.4875 - f1_flipped: 0.0750 - val_loss: 0.6949 - val_acc: 0.4500 - val_f1_score: 0.4500 - val_f1_flipped: 0.0000e+00\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.5750 - f1_score: 0.4500 - f1_flipped: 0.1250 - val_loss: 0.6947 - val_acc: 0.5000 - val_f1_score: 0.4000 - val_f1_flipped: 0.1000\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6834 - acc: 0.6375 - f1_score: 0.4625 - f1_flipped: 0.1750 - val_loss: 0.6947 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6774 - acc: 0.6875 - f1_score: 0.4875 - f1_flipped: 0.2000 - val_loss: 0.6953 - val_acc: 0.5500 - val_f1_score: 0.4500 - val_f1_flipped: 0.1000\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6782 - acc: 0.5750 - f1_score: 0.4500 - f1_flipped: 0.1250 - val_loss: 0.6958 - val_acc: 0.5000 - val_f1_score: 0.4000 - val_f1_flipped: 0.1000\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6787 - acc: 0.6625 - f1_score: 0.4750 - f1_flipped: 0.1875 - val_loss: 0.6956 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6769 - acc: 0.5875 - f1_score: 0.4500 - f1_flipped: 0.1375 - val_loss: 0.6963 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6713 - acc: 0.6500 - f1_score: 0.4875 - f1_flipped: 0.1625 - val_loss: 0.6968 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6651 - acc: 0.6375 - f1_score: 0.4500 - f1_flipped: 0.1875 - val_loss: 0.6972 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6565 - acc: 0.7250 - f1_score: 0.4750 - f1_flipped: 0.2500 - val_loss: 0.6979 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6600 - acc: 0.6875 - f1_score: 0.4750 - f1_flipped: 0.2125 - val_loss: 0.6984 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6875 - f1_score: 0.4625 - f1_flipped: 0.2250 - val_loss: 0.6994 - val_acc: 0.5500 - val_f1_score: 0.3500 - val_f1_flipped: 0.2000\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6549 - acc: 0.6875 - f1_score: 0.4375 - f1_flipped: 0.2500 - val_loss: 0.6988 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6750 - f1_score: 0.4250 - f1_flipped: 0.2500 - val_loss: 0.6991 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6393 - acc: 0.6875 - f1_score: 0.4125 - f1_flipped: 0.2750 - val_loss: 0.6997 - val_acc: 0.5500 - val_f1_score: 0.3000 - val_f1_flipped: 0.2500\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6400 - acc: 0.7250 - f1_score: 0.4625 - f1_flipped: 0.2625 - val_loss: 0.7035 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6335 - acc: 0.7375 - f1_score: 0.4375 - f1_flipped: 0.3000 - val_loss: 0.7077 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.6625 - f1_score: 0.4375 - f1_flipped: 0.2250 - val_loss: 0.7142 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6345 - acc: 0.6750 - f1_score: 0.4500 - f1_flipped: 0.2250 - val_loss: 0.7145 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6081 - acc: 0.7500 - f1_score: 0.4625 - f1_flipped: 0.2875 - val_loss: 0.7127 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6228 - acc: 0.6750 - f1_score: 0.4250 - f1_flipped: 0.2500 - val_loss: 0.7188 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6161 - acc: 0.6625 - f1_score: 0.4125 - f1_flipped: 0.2500 - val_loss: 0.7237 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6074 - acc: 0.6875 - f1_score: 0.4250 - f1_flipped: 0.2625 - val_loss: 0.7330 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6072 - acc: 0.7500 - f1_score: 0.4625 - f1_flipped: 0.2875 - val_loss: 0.7304 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6190 - acc: 0.7125 - f1_score: 0.3750 - f1_flipped: 0.3375 - val_loss: 0.7287 - val_acc: 0.4500 - val_f1_score: 0.2000 - val_f1_flipped: 0.2500\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5858 - acc: 0.7125 - f1_score: 0.4125 - f1_flipped: 0.3000 - val_loss: 0.7456 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6031 - acc: 0.6875 - f1_score: 0.4375 - f1_flipped: 0.2500 - val_loss: 0.7540 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5696 - acc: 0.7375 - f1_score: 0.4500 - f1_flipped: 0.2875 - val_loss: 0.7557 - val_acc: 0.5000 - val_f1_score: 0.3000 - val_f1_flipped: 0.2000\n",
            "model trained in 7.098 seconds\n",
            "current cross-validation mean accuracy: 0.540, f1: 0.310, and f1 flipped: 0.230\n",
            "cross-validation total time: 7.114 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "36-ZO9KhisUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "34dad476-2f93-453f-8528-e68c5afdee02"
      },
      "cell_type": "code",
      "source": [
        "print(*results, sep='\\n')\n",
        "print('cross-validation mean accuracy: {:.3f}, f1: {:.3f}, and f1 flipped: {:.3f}'.format(\n",
        "       *[np.mean([r[key] for r in results]) for key in results[0].keys()]))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'acc': 0.6000000238418579, 'F1': 0.30000001192092896, 'F1-flipped': 0.30000001192092896}\n",
            "{'acc': 0.44999998807907104, 'F1': 0.30000001192092896, 'F1-flipped': 0.15000000596046448}\n",
            "{'acc': 0.550000011920929, 'F1': 0.25, 'F1-flipped': 0.30000001192092896}\n",
            "{'acc': 0.6000000238418579, 'F1': 0.4000000059604645, 'F1-flipped': 0.20000000298023224}\n",
            "{'acc': 0.5, 'F1': 0.30000001192092896, 'F1-flipped': 0.20000000298023224}\n",
            "cross-validation mean accuracy: 0.540, f1: 0.310, and f1 flipped: 0.230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qetwgRrKf7X0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwnJvlslTcxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}